{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction and Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Objectives\n",
    ">**1. Reduce** the amount of data\n",
    "\n",
    ">**2. Preserve** the useful information (e.g. edge, corner, shape)\n",
    "\n",
    ">**3. Discard** the redundant information (e.g. lighting conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 1D Edge Detection\n",
    "* **Step 1. Smooth the signal to suppress noise**\n",
    "\n",
    "  * Convolve the signal $I(x)$ with a Gaussian kernel $g_\\sigma(x)$\n",
    "  * **Small $\\sigma \\rightarrow$** Large cutoff frequency $\\rightarrow$ **Preserve detail**\n",
    "  * **Large $\\sigma \\rightarrow$** Small cutoff frequency $\\rightarrow$ **Suppress detail**\n",
    "\n",
    ">$$g_\\sigma(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\n",
    ">$$\\;$$\n",
    ">\\begin{align}\n",
    "s(x)=g_\\sigma(x) * I(x)&=\\int_{-\\infty}^{\\infty}g_\\sigma(u)I(x-u)du\\\\\n",
    "&=\\int_{-\\infty}^{\\infty}g_\\sigma(x-u)I(u)du\n",
    "\\end{align}\n",
    "\n",
    "* **Step 2-a. Compute $s'(x)$ and look for maxima & minima**\n",
    "\n",
    "  * Instead of doing two convlutions,\n",
    "  * Using the derivative theorem of convolution,\n",
    "\n",
    ">$$s'(x)=\\frac{d}{dx} [ g_\\sigma(x) * I(x) ] = g'_\\sigma(x)*I(x)$$\n",
    "\n",
    "* **Step 2-b. Compute $s''(x)$ and look for zero-crossings**\n",
    "\n",
    "  * The signal is convolved with the **Laplacian of a Gaussian**\n",
    "\n",
    ">$$s''(x)=g''_\\sigma(x)*I(x)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 2D Edge Detection - Canny (1986)\n",
    "* **Step 1. Convolve with a 2D Gaussian $G_\\sigma(x,y)$**\n",
    "\n",
    ">\\begin{align}\n",
    "G_\\sigma(x,y)&=\\frac{1}{2\\pi\\sigma^2}\\exp\\left(-\\frac{x^2+y^2}{2\\sigma^2}\\right)\\\\\n",
    "\\\\\n",
    "S(x,y)&=G_\\sigma(x,y)*I(x,y)\\\\\n",
    "\\\\\n",
    "&=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}G_\\sigma(u,v)I(x-u,y-v)du dv\n",
    "\\end{align}\n",
    "\n",
    "* **Step 2. Find the Gradient of $S(x,y)$**\n",
    "\n",
    ">\\begin{align}\n",
    "\\nabla S &=\\nabla (G_\\sigma*I) \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial (G_\\sigma *I)}{\\partial x} \\\\\n",
    "    \\frac{\\partial (G_\\sigma *I)}{\\partial y} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial G_\\sigma}{\\partial x} *I \\\\\n",
    "    \\frac{\\partial G_\\sigma}{\\partial y} *I \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "* **Step 3. Non-maximal Suppression**\n",
    "\n",
    ">$$\\text{Edge elements (edgels) are placed where } \\mid \\nabla S \\mid \\text{ is greater than local values in the direction of } \\pm \\nabla S $$\n",
    "  \n",
    "* **Step 4. Threshold the Edgels**\n",
    "\n",
    ">$$\\text{Output: edgel positions, each with strength } \\mid \\nabla S \\mid \\text{ and orientation } \\nabla S \\text{/} \\mid \\nabla S \\mid$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. 2D Edge Detection - Marr and Hildreth (1980)\n",
    "* Unlike Canny edge detector, Marr-Hildreth operator is **isotropic**\n",
    "* **Algorithm: Find the zero-crossings of:**\n",
    "\n",
    ">$$\\nabla^2G_\\sigma*I$$\n",
    ">$$\\;$$\n",
    ">$$\\text{where } \\nabla^2G_\\sigma=\\left( \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2} \\right) G_\\sigma \\text{ is the Laplacian of } G_\\sigma$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Implementation Details\n",
    "* **Convolution**\n",
    "\n",
    ">$$S(x,y)=\\sum_{u=-n}^{n} \\sum_{v=-n}^{n} G_\\sigma(u,v)I(x-u,y-v)$$\n",
    ">\n",
    ">* Kernels are trucated so that the discarded samples are less than $1/1000$ of the peak value\n",
    ">* $\\pm 3\\sigma$ is often enough\n",
    ">* Smaller $n$ leads to sharp discontinuity (avoid!)\n",
    ">\n",
    "|$\\sigma$|1.0|1.5|3|6|\n",
    "|-|-|-|-|-|\n",
    "|$2n$ $+1$|7|11|23|45|\n",
    ">\n",
    ">* 2D Convolution: computationally expensive!\n",
    ">* Decompose it into two 1D convolutions\n",
    ">$$G_\\sigma(x,y)*I(x,y)=g_\\sigma(x)*[g_\\sigma(y)*I(x,y)]$$\n",
    ">\n",
    ">$$\\mathcal{O} \\left((2n+1)^2 \\right) \\text{ vs. } \\mathcal{O} \\left(2(2n+1)\\right)$$\n",
    "\n",
    "* **Differentiation** \n",
    "\n",
    ">$$\\frac{\\partial S}{\\partial x} \\approx \\frac{S(x+1,y)-S(x-1,y)}{2}$$\n",
    ">\n",
    ">* The above is the result of the **Taylor Expansion** of $S(x,y)$\n",
    ">* This is equivalent to convolving the rows of image samples with the kernel $(1/2, 0, -1/2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Normalised Cross-Correlation\n",
    "* **Normalised Cross-Correlation** between an image patch $P(x,y)$ and other image portion $I(x,y)$\n",
    "\n",
    ">$$c(x,y)=\\frac{\\sum^n_{u=-n}\\sum^n_{v=-n}P(u,v)I(x+u,y+v)}{\\sqrt{\\sum^n_{u=-n}\\sum^n_{v=-n}P^2(u,v)\\sum^n_{u=-n}\\sum^n_{v=-n}I^2(x+u,y+v)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Corner Detection - Harris (1987)\n",
    "\n",
    "* **Corner Detection** - Important in **tracking** objects and **matching** stereo pairs\n",
    "* Important in understanding **kinetic effect** and **ego-motion**\n",
    "* **Step 1. Calculate the change in intensity in direction $\\textbf{n}$**\n",
    "\n",
    "  * Here, $I$ is already smoothed\n",
    "\n",
    ">\\begin{align}\n",
    "I_n &\\equiv \\nabla I(x,y) \\cdot \\widehat{\\textbf{n}} \\equiv \\begin{bmatrix} I_x & I_y \\end{bmatrix}^T \\cdot \\widehat{\\textbf{n}}\\\\\n",
    "\\;\\\\\n",
    "I_n^2 &= \\frac{\\textbf{n}^T \\nabla I \\nabla I^T \\textbf{n}}{\\textbf{n}^T\\textbf{n}}\\\\\n",
    "\\;\\\\\n",
    "&= \\frac{\\textbf{n}^T \\begin{bmatrix} \n",
    "I_x^2 & I_xI_y \\\\\n",
    "I_xI_y & I_y^2\n",
    "\\end{bmatrix}\n",
    "\\textbf{n}}{\\textbf{n}^T\\textbf{n}}\n",
    "\\end{align}\n",
    ">$$\\;$$\n",
    ">$$\\text{where } I_x \\equiv \\frac{\\partial I}{\\partial x} \\text{ and } I_y \\equiv \\frac{\\partial I}{\\partial y}$$\n",
    "\n",
    "* **Step 2. Smooth $I_n^2$ by convolution with a Gaussian kernel**\n",
    "\n",
    ">\\begin{align}\n",
    "C_n(x,y) &= G_\\sigma (x,y)*I^2_n \\\\\n",
    "\\;\\\\\n",
    "&= \\frac{\\textbf{n}^T \\begin{bmatrix} \n",
    "\\left\\langle I_x^2 \\right\\rangle & \\left\\langle I_xI_y \\right\\rangle\\\\\n",
    "\\left\\langle I_xI_y \\right\\rangle & \\left\\langle I_y^2 \\right\\rangle\\\\\n",
    "\\end{bmatrix}\n",
    "\\textbf{n}}{\\textbf{n}^T\\textbf{n}}\n",
    "\\end{align}\n",
    ">$$\\;$$\n",
    ">$$\\text{where } \\left\\langle \\right\\rangle \\text{ is the smoothed value}$$\n",
    "\n",
    "* **Step 3. Use the eigenvalues of $\\text{A}$ to determine the structure**\n",
    "\n",
    ">$$C_n(x,y)=\\frac{\\textbf{n}^T \\text{A} \\textbf{n}}{\\textbf{n}^T\\textbf{n}}$$\n",
    ">$$\\;$$\n",
    ">$$\\text{where,} \\;\\;\\; \\text{A}=\\begin{bmatrix} \n",
    "\\left\\langle I_x^2 \\right\\rangle & \\left\\langle I_xI_y \\right\\rangle\\\\\n",
    "\\left\\langle I_xI_y \\right\\rangle & \\left\\langle I_y^2 \\right\\rangle\\\\\n",
    "\\end{bmatrix}$$\n",
    ">$$\\;$$\n",
    ">$$\\text{then,} \\;\\;\\; \\lambda_1 \\leq C_n(x,y) \\leq\\lambda_2$$\n",
    ">\n",
    ">* **$\\text{A}$**: Structure Tensor\n",
    ">* **No structure**(smooth): $\\lambda_1 \\approx \\lambda_2 \\approx 0$\n",
    ">* **1D structure**(edge): $\\lambda_1 \\approx 0$ (direction of edge), $\\lambda_2$ is large (normal to edge)\n",
    ">* **2D structure**(corner): $\\lambda_1$ and $\\lambda_2$ both large and distinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Setting Threshold for Corner Detection\n",
    "* **If $M_c$ exceeds some threshold $\\rightarrow$ Mark corners**\n",
    "\n",
    ">$$M_c=\\lambda_1 \\lambda_2-\\kappa(\\lambda_1+\\lambda_2)^2$$\n",
    ">$$\\;$$\n",
    ">$$M_c=\\det{\\text{A}} - \\kappa \\text{ tr A}$$\n",
    ">* The second form is preferable (low computational cost)\n",
    ">* $\\kappa$: generally range from $0.04$ to $0.15$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Blobs\n",
    "* Blob: area of uniform intensity in the image\n",
    "* They are localised in the middle of areas of similar intensity\n",
    "* Convolve with the **Laplacian of the Gaussian** $\\rightarrow$ Locate minimum\n",
    "* As $\\sigma$ increases, larger image features are detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Scale Space\n",
    "* Achieve scale independence by looking at different resolutions\n",
    "* **Scale Space**\n",
    "\n",
    ">\\begin{align}\n",
    "L(x,y,t)&=G(x,y,t)*I(x,y)\\\\\n",
    "\\;\\\\\n",
    "G(x,y,t)&=\\frac{1}{2\\pi t}\\exp{-\\frac{x^2+y^2}{2t}}\\\\\n",
    "\\;\\\\\n",
    "t&=\\sigma^2\n",
    "\\end{align}\n",
    "\n",
    "* **Choose discrete set of low-pass filter**\n",
    "\n",
    ">$$\\sigma_i=2^\\frac{1}{s}\\sigma_{i-1}=2^\\frac{i}{s}\\sigma_0$$\n",
    ">\n",
    ">* $\\sigma$ doubles after $s$ intervals ($=$ an **octave**)\n",
    ">* Avoid blurring with large scales by **subsampling** the image after each octave\n",
    ">* $\\Rightarrow$ **Image Pyramid**\n",
    "\n",
    "* **Within each octave, we convolve repeatedly**\n",
    "\n",
    ">$$G(\\sigma_1)*G(\\sigma_2)=G\\left(\\sqrt{\\sigma^2_1+\\sigma^2_2}\\right)$$\n",
    ">\n",
    ">* The following should be satisfied:\n",
    ">\n",
    ">$$G(\\sigma_{i+1})=G(\\sigma_i)*G(\\sigma_k)$$\n",
    ">\n",
    ">* $\\sigma_k$ can be calculated\n",
    ">\n",
    ">\\begin{align}\n",
    "\\sigma_k&=\\sqrt{\\sigma_{i+1}^2-\\sigma_i^2}\\\\\n",
    "\\sigma_{i+1}&=2^{\\frac{1}{s}}\\sigma_i\\\\\n",
    "\\sigma_k&=\\sigma_i\\sqrt{2^{\\frac{2}{s}}-1}\n",
    "\\end{align}\n",
    "\n",
    "* **Ideal scale for a keypoint is located at the maximum of the scale space**\n",
    "  * $\\Rightarrow$ The largest value of the samples in the pyramid is obtained and interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11. DoG - Difference of Gaussians\n",
    "* **DoG: Blob Detector**\n",
    "  * Calculated as the difference of two Gaussians (small $\\sigma$ - high $\\sigma$)\n",
    "  * This approximates the Laplacian of a Gaussian\n",
    "* **Blobs are Important**\n",
    "  * Blobs are usually found inside of objects (as opposed to edges)\n",
    "  * Thus they are less likely to contain background in queries\n",
    "  * +) stability, repeatability, definite optimal scale, ...\n",
    "* **Scale Space Pyramid**\n",
    "  * Subtract one member of a pyramid level from the one directly above it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.12. Zero Normalised Patches\n",
    "* **Matching intensity patches**\n",
    "\n",
    ">$$CC(P_1, P_2)=\\sum_i^N{P_1[i]P_2[i]}$$\n",
    ">\n",
    ">* Not robust to changes (brightness & contrast)\n",
    "\n",
    "* **Zero Normalised Patches**\n",
    "\n",
    ">$$ZN(x,y)=\\frac{Z(x,y)}{\\sigma}=\\frac{I(x,y)-\\mu}{\\sigma}$$\n",
    ">\n",
    ">* Robust to changes\n",
    ">* Patches can be matched using simple cross-correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.13. Matching Patches using Intensity Edges\n",
    "* **Orientation Histograms**\n",
    "\n",
    ">1. Find every edge in a patch of pixels\n",
    ">2. Weight them by the strength of the edge\n",
    ">3. Bin them together into an orientation histogram\n",
    "\n",
    "* **Advantage**\n",
    "\n",
    ">1. Robust to brightness and contrast changes\n",
    ">2. Incorporates orientation data $\\rightarrow$ robust to orientation\n",
    "\n",
    "* **SIFT**(Scale Invariant Feature Transform)** interest point descriptor**\n",
    "\n",
    ">1. $N\\times N$ patch (typically, $N=16$)\n",
    ">2. Split this patch into $c$ cells (typically $c=16$)\n",
    ">3. In each cell, obtain the orientation histogram\n",
    ">4. Weight them with a Gaussian window ($\\sigma=0.5\\;\\times$ the scale of the feature centered on the patch)\n",
    ">5. The resulting descriptor is $d\\times c$ vector (typically $\\textbf{128}\\text{D}$)\n",
    ">6. Normalise the descriptor vector (invariance to gradient magnitude change)\n",
    ">7. Threshold the elements ($0.2$) $\\rightarrow$ Renormalise (reduce the effect of non-affine lighting changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.13. Texture\n",
    "* **What is Texture?**\n",
    "\n",
    ">* **Image Texture** consists of organised patterns of regular sub-elements called **textons**\n",
    "\n",
    "* **Characterising Texture**\n",
    "\n",
    ">* **Filter bank**:\n",
    ">  * $8$ Lablacian of Gaussian filters\n",
    ">  * $4$ Gaussian filters at different scales\n",
    ">  * $36$ Oriented filters\n",
    ">    * $6$ Different angles\n",
    ">    * $3$ Different scales\n",
    ">    * $2$ Different phases ($1^{st} \\text{&}\\; 2^{nd}$ derivatives of Gaussians on the minor axis)\n",
    ">* **Descriptor**:\n",
    ">  * Simply the concatenated responses of all the filters at a pixel\n",
    ">  * This is innately immune to most changes in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feature Extraction and Description\n",
    "\n",
    "## 2.1. Objectives\n",
    ">**1. Reduce** the amount of data\n",
    "\n",
    ">**2. Preserve** the useful information (e.g. edge, corner, shape)\n",
    "\n",
    ">**3. Discard** the redundant information (e.g. lighting conditions)\n",
    "\n",
    "## 2.2. 1D Edge Detection\n",
    "* **Step 1. Smooth the signal to suppress noise**\n",
    "\n",
    "  * Convolve the signal $I(x)$ with a Gaussian kernel $g_\\sigma(x)$\n",
    "  * **Small $\\sigma \\rightarrow$** Large cutoff frequency $\\rightarrow$ **Preserve detail**\n",
    "  * **Large $\\sigma \\rightarrow$** Small cutoff frequency $\\rightarrow$ **Suppress detail**\n",
    "\n",
    ">$$g_\\sigma(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\n",
    ">$$\\;$$\n",
    ">\\begin{align}\n",
    "s(x)=g_\\sigma(x) * I(x)&=\\int_{-\\infty}^{\\infty}g_\\sigma(u)I(x-u)du\\\\\n",
    "&=\\int_{-\\infty}^{\\infty}g_\\sigma(x-u)I(u)du\n",
    "\\end{align}\n",
    "\n",
    "* **Step 2-a. Compute $s'(x)$ and look for maxima & minima**\n",
    "\n",
    "  * Instead of doing two convlutions,\n",
    "  * Using the derivative theorem of convolution,\n",
    "\n",
    ">$$s'(x)=\\frac{d}{dx} [ g_\\sigma(x) * I(x) ] = g'_\\sigma(x)*I(x)$$\n",
    "\n",
    "* **Step 2-b. Compute $s''(x)$ and look for zero-crossings**\n",
    "\n",
    "  * The signal is convolved with the **Laplacian of a Gaussian**\n",
    "\n",
    ">$$s''(x)=g''_\\sigma(x)*I(x)$$\n",
    "\n",
    "\n",
    "\n",
    "## 2.3. 2D Edge Detection - Canny (1986)\n",
    "* **Step 1. Convolve with a 2D Gaussian $G_\\sigma(x,y)$**\n",
    "\n",
    ">\\begin{align}\n",
    "G_\\sigma(x,y)&=\\frac{1}{2\\pi\\sigma^2}\\exp\\left(-\\frac{x^2+y^2}{2\\sigma^2}\\right)\\\\\n",
    "\\\\\n",
    "S(x,y)&=G_\\sigma(x,y)*I(x,y)\\\\\n",
    "\\\\\n",
    "&=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}G_\\sigma(u,v)I(x-u,y-v)du dv\n",
    "\\end{align}\n",
    "\n",
    "* **Step 2. Find the Gradient of $S(x,y)$**\n",
    "\n",
    ">\\begin{align}\n",
    "\\nabla S &=\\nabla (G_\\sigma*I) \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial (G_\\sigma *I)}{\\partial x} \\\\\n",
    "    \\frac{\\partial (G_\\sigma *I)}{\\partial y} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial G_\\sigma}{\\partial x} *I \\\\\n",
    "    \\frac{\\partial G_\\sigma}{\\partial y} *I \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "* **Step 3. Non-maximal Suppression**\n",
    "\n",
    ">$$\\text{Edge elements (edgels) are placed where } \\mid \\nabla S \\mid \\text{ is greater than local values in the direction of } \\pm \\nabla S $$\n",
    "  \n",
    "* **Step 4. Threshold the Edgels**\n",
    "\n",
    ">$$\\text{Output: edgel positions, each with strength } \\mid \\nabla S \\mid \\text{ and orientation } \\nabla S \\text{/} \\mid \\nabla S \\mid$$\n",
    "\n",
    "## 2.4. 2D Edge Detection - Marr and Hildreth (1980)\n",
    "* Unlike Canny edge detector, Marr-Hildreth operator is **isotropic**\n",
    "* **Algorithm: Find the zero-crossings of:**\n",
    "\n",
    ">$$\\nabla^2G_\\sigma*I$$\n",
    ">$$\\;$$\n",
    ">$$\\text{where } \\nabla^2G_\\sigma=\\left( \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2} \\right) G_\\sigma \\text{ is the Laplacian of } G_\\sigma$$\n",
    "\n",
    "## 2.5. Implementation Details\n",
    "* **Convolution**\n",
    "\n",
    ">$$S(x,y)=\\sum_{u=-n}^{n} \\sum_{v=-n}^{n} G_\\sigma(u,v)I(x-u,y-v)$$\n",
    ">\n",
    ">* Kernels are trucated so that the discarded samples are less than $1/1000$ of the peak value\n",
    ">* $\\pm 3\\sigma$ is often enough\n",
    ">* Smaller $n$ leads to sharp discontinuity (avoid!)\n",
    ">\n",
    "|$\\sigma$|1.0|1.5|3|6|\n",
    "|-|-|-|-|-|\n",
    "|$2n$ $+1$|7|11|23|45|\n",
    ">\n",
    ">* 2D Convolution: computationally expensive!\n",
    ">* Decompose it into two 1D convolutions\n",
    ">$$G_\\sigma(x,y)*I(x,y)=g_\\sigma(x)*[g_\\sigma(y)*I(x,y)]$$\n",
    ">\n",
    ">$$\\mathcal{O} \\left((2n+1)^2 \\right) \\text{ vs. } \\mathcal{O} \\left(2(2n+1)\\right)$$\n",
    "\n",
    "* **Differentiation** \n",
    "\n",
    ">$$\\frac{\\partial S}{\\partial x} \\approx \\frac{S(x+1,y)-S(x-1,y)}{2}$$\n",
    ">\n",
    ">* The above is the result of the **Taylor Expansion** of $S(x,y)$\n",
    ">* This is equivalent to convolving the rows of image samples with the kernel $(1/2, 0, -1/2)$\n",
    "\n",
    "## 2.6. Normalised Cross-Correlation\n",
    "* **Normalised Cross-Correlation** between an image patch $P(x,y)$ and other image portion $I(x,y)$\n",
    "\n",
    ">$$c(x,y)=\\frac{\\sum^n_{u=-n}\\sum^n_{v=-n}P(u,v)I(x+u,y+v)}{\\sqrt{\\sum^n_{u=-n}\\sum^n_{v=-n}P^2(u,v)\\sum^n_{u=-n}\\sum^n_{v=-n}I^2(x+u,y+v)}}$$\n",
    "\n",
    "## 2.7. Corner Detection - Harris (1987)\n",
    "\n",
    "* **Corner Detection** - Important in **tracking** objects and **matching** stereo pairs\n",
    "* Important in understanding **kinetic effect** and **ego-motion**\n",
    "* **Step 1. Calculate the change in intensity in direction $\\textbf{n}$**\n",
    "\n",
    "  * Here, $I$ is already smoothed\n",
    "\n",
    ">\\begin{align}\n",
    "I_n &\\equiv \\nabla I(x,y) \\cdot \\widehat{\\textbf{n}} \\equiv \\begin{bmatrix} I_x & I_y \\end{bmatrix}^T \\cdot \\widehat{\\textbf{n}}\\\\\n",
    "\\;\\\\\n",
    "I_n^2 &= \\frac{\\textbf{n}^T \\nabla I \\nabla I^T \\textbf{n}}{\\textbf{n}^T\\textbf{n}}\\\\\n",
    "\\;\\\\\n",
    "&= \\frac{\\textbf{n}^T \\begin{bmatrix} \n",
    "I_x^2 & I_xI_y \\\\\n",
    "I_xI_y & I_y^2\n",
    "\\end{bmatrix}\n",
    "\\textbf{n}}{\\textbf{n}^T\\textbf{n}}\n",
    "\\end{align}\n",
    ">$$\\;$$\n",
    ">$$\\text{where } I_x \\equiv \\frac{\\partial I}{\\partial x} \\text{ and } I_y \\equiv \\frac{\\partial I}{\\partial y}$$\n",
    "\n",
    "* **Step 2. Smooth $I_n^2$ by convolution with a Gaussian kernel**\n",
    "\n",
    ">\\begin{align}\n",
    "C_n(x,y) &= G_\\sigma (x,y)*I^2_n \\\\\n",
    "\\;\\\\\n",
    "&= \\frac{\\textbf{n}^T \\begin{bmatrix} \n",
    "\\left\\langle I_x^2 \\right\\rangle & \\left\\langle I_xI_y \\right\\rangle\\\\\n",
    "\\left\\langle I_xI_y \\right\\rangle & \\left\\langle I_y^2 \\right\\rangle\\\\\n",
    "\\end{bmatrix}\n",
    "\\textbf{n}}{\\textbf{n}^T\\textbf{n}}\n",
    "\\end{align}\n",
    ">$$\\;$$\n",
    ">$$\\text{where } \\left\\langle \\right\\rangle \\text{ is the smoothed value}$$\n",
    "\n",
    "* **Step 3. Use the eigenvalues of $\\text{A}$ to determine the structure**\n",
    "\n",
    ">$$C_n(x,y)=\\frac{\\textbf{n}^T \\text{A} \\textbf{n}}{\\textbf{n}^T\\textbf{n}}$$\n",
    ">$$\\;$$\n",
    ">$$\\text{where,} \\;\\;\\; \\text{A}=\\begin{bmatrix} \n",
    "\\left\\langle I_x^2 \\right\\rangle & \\left\\langle I_xI_y \\right\\rangle\\\\\n",
    "\\left\\langle I_xI_y \\right\\rangle & \\left\\langle I_y^2 \\right\\rangle\\\\\n",
    "\\end{bmatrix}$$\n",
    ">$$\\;$$\n",
    ">$$\\text{then,} \\;\\;\\; \\lambda_1 \\leq C_n(x,y) \\leq\\lambda_2$$\n",
    ">\n",
    ">* **$\\text{A}$**: Structure Tensor\n",
    ">* **No structure**(smooth): $\\lambda_1 \\approx \\lambda_2 \\approx 0$\n",
    ">* **1D structure**(edge): $\\lambda_1 \\approx 0$ (direction of edge), $\\lambda_2$ is large (normal to edge)\n",
    ">* **2D structure**(corner): $\\lambda_1$ and $\\lambda_2$ both large and distinct\n",
    "\n",
    "## 2.8. Setting Threshold for Corner Detection\n",
    "* **If $M_c$ exceeds some threshold $\\rightarrow$ Mark corners**\n",
    "\n",
    ">$$M_c=\\lambda_1 \\lambda_2-\\kappa(\\lambda_1+\\lambda_2)^2$$\n",
    ">$$\\;$$\n",
    ">$$M_c=\\det{\\text{A}} - \\kappa \\text{ tr A}$$\n",
    ">* The second form is preferable (low computational cost)\n",
    ">* $\\kappa$: generally range from $0.04$ to $0.15$\n",
    "\n",
    "## 2.9. Blobs\n",
    "* Blob: area of uniform intensity in the image\n",
    "* They are localised in the middle of areas of similar intensity\n",
    "* Convolve with the **Laplacian of the Gaussian** $\\rightarrow$ Locate minimum\n",
    "* As $\\sigma$ increases, larger image features are detected\n",
    "\n",
    "## 2.10. Scale Space\n",
    "* Achieve scale independence by looking at different resolutions\n",
    "* **Scale Space**\n",
    "\n",
    ">\\begin{align}\n",
    "L(x,y,t)&=G(x,y,t)*I(x,y)\\\\\n",
    "\\;\\\\\n",
    "G(x,y,t)&=\\frac{1}{2\\pi t}\\exp{-\\frac{x^2+y^2}{2t}}\\\\\n",
    "\\;\\\\\n",
    "t&=\\sigma^2\n",
    "\\end{align}\n",
    "\n",
    "* **Choose discrete set of low-pass filter**\n",
    "\n",
    ">$$\\sigma_i=2^\\frac{1}{s}\\sigma_{i-1}=2^\\frac{i}{s}\\sigma_0$$\n",
    ">\n",
    ">* $\\sigma$ doubles after $s$ intervals ($=$ an **octave**)\n",
    ">* Avoid blurring with large scales by **subsampling** the image after each octave\n",
    ">* $\\Rightarrow$ **Image Pyramid**\n",
    "\n",
    "* **Within each octave, we convolve repeatedly**\n",
    "\n",
    ">$$G(\\sigma_1)*G(\\sigma_2)=G\\left(\\sqrt{\\sigma^2_1+\\sigma^2_2}\\right)$$\n",
    ">\n",
    ">* The following should be satisfied:\n",
    ">\n",
    ">$$G(\\sigma_{i+1})=G(\\sigma_i)*G(\\sigma_k)$$\n",
    ">\n",
    ">* $\\sigma_k$ can be calculated\n",
    ">\n",
    ">\\begin{align}\n",
    "\\sigma_k&=\\sqrt{\\sigma_{i+1}^2-\\sigma_i^2}\\\\\n",
    "\\sigma_{i+1}&=2^{\\frac{1}{s}}\\sigma_i\\\\\n",
    "\\sigma_k&=\\sigma_i\\sqrt{2^{\\frac{2}{s}}-1}\n",
    "\\end{align}\n",
    "\n",
    "* **Ideal scale for a keypoint is located at the maximum of the scale space**\n",
    "  * $\\Rightarrow$ The largest value of the samples in the pyramid is obtained and interpolated\n",
    "\n",
    "## 2.11. DoG - Difference of Gaussians\n",
    "* **DoG: Blob Detector**\n",
    "  * Calculated as the difference of two Gaussians (small $\\sigma$ - high $\\sigma$)\n",
    "  * This approximates the Laplacian of a Gaussian\n",
    "* **Blobs are Important**\n",
    "  * Blobs are usually found inside of objects (as opposed to edges)\n",
    "  * Thus they are less likely to contain background in queries\n",
    "  * +) stability, repeatability, definite optimal scale, ...\n",
    "* **Scale Space Pyramid**\n",
    "  * Subtract one member of a pyramid level from the one directly above it\n",
    "\n",
    "## 2.12. Zero Normalised Patches\n",
    "* **Matching intensity patches**\n",
    "\n",
    ">$$CC(P_1, P_2)=\\sum_i^N{P_1[i]P_2[i]}$$\n",
    ">\n",
    ">* Not robust to changes (brightness & contrast)\n",
    "\n",
    "* **Zero Normalised Patches**\n",
    "\n",
    ">$$ZN(x,y)=\\frac{Z(x,y)}{\\sigma}=\\frac{I(x,y)-\\mu}{\\sigma}$$\n",
    ">\n",
    ">* Robust to changes\n",
    ">* Patches can be matched using simple cross-correlation\n",
    "\n",
    "## 2.13. Matching Patches using Intensity Edges\n",
    "* **Orientation Histograms**\n",
    "\n",
    ">1. Find every edge in a patch of pixels\n",
    ">2. Weight them by the strength of the edge\n",
    ">3. Bin them together into an orientation histogram\n",
    "\n",
    "* **Advantage**\n",
    "\n",
    ">1. Robust to brightness and contrast changes\n",
    ">2. Incorporates orientation data $\\rightarrow$ robust to orientation\n",
    "\n",
    "* **SIFT**(Scale Invariant Feature Transform)** interest point descriptor**\n",
    "\n",
    ">1. $N\\times N$ patch (typically, $N=16$)\n",
    ">2. Split this patch into $c$ cells (typically $c=16$)\n",
    ">3. In each cell, obtain the orientation histogram\n",
    ">4. Weight them with a Gaussian window ($\\sigma=0.5\\;\\times$ the scale of the feature centered on the patch)\n",
    ">5. The resulting descriptor is $d\\times c$ vector (typically $\\textbf{128}\\text{D}$)\n",
    ">6. Normalise the descriptor vector (invariance to gradient magnitude change)\n",
    ">7. Threshold the elements ($0.2$) $\\rightarrow$ Renormalise (reduce the effect of non-affine lighting changes)\n",
    "\n",
    "## 2.13. Texture\n",
    "* **What is Texture?**\n",
    "\n",
    ">* **Image Texture** consists of organised patterns of regular sub-elements called **textons**\n",
    "\n",
    "* **Characterising Texture**\n",
    "\n",
    ">* **Filter bank**:\n",
    ">  * $8$ Lablacian of Gaussian filters\n",
    ">  * $4$ Gaussian filters at different scales\n",
    ">  * $36$ Oriented filters\n",
    ">    * $6$ Different angles\n",
    ">    * $3$ Different scales\n",
    ">    * $2$ Different phases ($1^{st} \\text{&}\\; 2^{nd}$ derivatives of Gaussians on the minor axis)\n",
    ">* **Descriptor**:\n",
    ">  * Simply the concatenated responses of all the filters at a pixel\n",
    ">  * This is innately immune to most changes in an image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
