{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction and Description\n",
    "\n",
    ">1. **Reduce** the amount of data\n",
    ">2. **Preserve** useful information (e.g. edge, corner, shape)\n",
    ">3. **Discard** redundant information (e.g. lighting conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. 1D Edge Detection\n",
    "* **Step 1. Smooth the signal to suppress noise**\n",
    "\n",
    "  * Convolve the signal $I(x)$ with a Gaussian kernel $g_\\sigma(x)$\n",
    "  * **Small $\\sigma \\rightarrow$** Large cutoff frequency $\\rightarrow$ **Preserve detail**\n",
    "  * **Large $\\sigma \\rightarrow$** Small cutoff frequency $\\rightarrow$ **Suppress detail**\n",
    "\n",
    ">$$g_\\sigma(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\n",
    ">$$\\;$$\n",
    ">\\begin{align}\n",
    "s(x)=g_\\sigma(x) * I(x)&=\\int_{-\\infty}^{\\infty}g_\\sigma(u)I(x-u)du\\\\\n",
    "&=\\int_{-\\infty}^{\\infty}g_\\sigma(x-u)I(u)du\n",
    "\\end{align}\n",
    "\n",
    "* **Step 2-a. Compute $s'(x)$ and look for maxima & minima**\n",
    "\n",
    "  * From the derivative theorem of convolution,\n",
    "  \n",
    ">$$s'(x)=\\frac{d}{dx} [ g_\\sigma(x) * I(x) ] = g'_\\sigma(x)*I(x)$$\n",
    "\n",
    "* **Step 2-b. Compute $s''(x)$ and look for zero-crossings**\n",
    "\n",
    "  * The signal is convolved with the **Laplacian of a Gaussian**\n",
    "\n",
    ">$$s''(x)=g''_\\sigma(x)*I(x)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. 2D Edge Detection - Canny (1986)\n",
    "* **Step 1. Convolve with a 2D Gaussian $G_\\sigma(x,y)$**\n",
    "\n",
    ">\\begin{align}\n",
    "G_\\sigma(x,y)&=\\frac{1}{2\\pi\\sigma^2}\\exp\\left(-\\frac{x^2+y^2}{2\\sigma^2}\\right)\\\\\n",
    "\\\\\n",
    "S(x,y)&=G_\\sigma(x,y)*I(x,y)\\\\\n",
    "\\\\\n",
    "&=\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}G_\\sigma(u,v)I(x-u,y-v)du dv\n",
    "\\end{align}\n",
    "\n",
    "* **Step 2. Find the Gradient of $S(x,y)$**\n",
    "\n",
    ">\\begin{align}\n",
    "\\nabla S &=\\nabla (G_\\sigma*I) \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial (G_\\sigma *I)}{\\partial x} \\\\\n",
    "    \\frac{\\partial (G_\\sigma *I)}{\\partial y} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial G_\\sigma}{\\partial x} *I \\\\\n",
    "    \\frac{\\partial G_\\sigma}{\\partial y} *I \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "* **Step 3. Non-maximal Suppression**\n",
    "\n",
    ">$$\\text{Edge elements (edgels) are placed where } | \\nabla S | \\text{ is greater than local values in the direction of } \\pm \\nabla S $$\n",
    "  \n",
    "* **Step 4. Threshold the Edgels**\n",
    "\n",
    ">$$\\text{Output: edgel positions, each with strength } |\\nabla S| \\text{ and orientation } \\nabla S /|\\nabla S|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 2D Edge Detection - Marr and Hildreth (1980)\n",
    "* Unlike Canny edge detector, Marr-Hildreth operator is **isotropic**\n",
    "* **Algorithm: Find the zero-crossings of:**\n",
    "\n",
    ">$$\\nabla^2G_\\sigma*I$$\n",
    ">$$\\;$$\n",
    ">$$\\text{where } \\nabla^2G_\\sigma=\\left( \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2} \\right) G_\\sigma \\text{ is the Laplacian of } G_\\sigma$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Corner Detection - Harris (1987)\n",
    "\n",
    "* **Corner Detection** - Important in **tracking** objects and **matching** stereo pairs\n",
    "* Important in understanding **kinetic effect** and **ego-motion**\n",
    "* **Step 1. Calculate the change in intensity in direction $\\textbf{n}$**\n",
    "\n",
    "  * Here, $I$ is already smoothed\n",
    "\n",
    ">\\begin{align}\n",
    "I_n &\\equiv \\nabla I(x,y) \\cdot \\widehat{\\textbf{n}} \\equiv \\begin{bmatrix} I_x & I_y \\end{bmatrix}^T \\cdot \\widehat{\\textbf{n}}\\\\\n",
    "\\;\\\\\n",
    "I_n^2 &= \\frac{\\textbf{n}^T \\nabla I \\nabla I^T \\textbf{n}}{\\textbf{n}^T\\textbf{n}}\\\\\n",
    "\\;\\\\\n",
    "&= \\frac{\\textbf{n}^T \\begin{bmatrix} \n",
    "I_x^2 & I_xI_y \\\\\n",
    "I_xI_y & I_y^2\n",
    "\\end{bmatrix}\n",
    "\\textbf{n}}{\\textbf{n}^T\\textbf{n}}\n",
    "\\end{align}\n",
    ">$$\\;$$\n",
    ">$$\\text{where } I_x \\equiv \\frac{\\partial I}{\\partial x} \\text{ and } I_y \\equiv \\frac{\\partial I}{\\partial y}$$\n",
    "\n",
    "* **Step 2. Smooth $I_n^2$ by convolution with a Gaussian kernel**\n",
    "\n",
    ">\\begin{align}\n",
    "C_n(x,y) &= G_\\sigma (x,y)*I^2_n \\\\\n",
    "\\;\\\\\n",
    "&= \\frac{\\textbf{n}^T \\begin{bmatrix} \n",
    "\\left\\langle I_x^2 \\right\\rangle & \\left\\langle I_xI_y \\right\\rangle\\\\\n",
    "\\left\\langle I_xI_y \\right\\rangle & \\left\\langle I_y^2 \\right\\rangle\\\\\n",
    "\\end{bmatrix}\n",
    "\\textbf{n}}{\\textbf{n}^T\\textbf{n}}\n",
    "\\end{align}\n",
    ">$$\\;$$\n",
    ">$$\\text{where } \\left\\langle \\right\\rangle \\text{ is the smoothed value}$$\n",
    "\n",
    "* **Step 3. Use the eigenvalues of $\\text{A}$ to determine the structure (Rayleigh's Quotient)**\n",
    "\n",
    ">$$C_n(x,y)=\\frac{\\textbf{n}^T \\text{A} \\textbf{n}}{\\textbf{n}^T\\textbf{n}}$$\n",
    ">$$\\;$$\n",
    ">$$\\text{where,} \\;\\;\\; \\text{A}=\\begin{bmatrix} \n",
    "\\left\\langle I_x^2 \\right\\rangle & \\left\\langle I_xI_y \\right\\rangle\\\\\n",
    "\\left\\langle I_xI_y \\right\\rangle & \\left\\langle I_y^2 \\right\\rangle\\\\\n",
    "\\end{bmatrix}$$\n",
    ">$$\\;$$\n",
    ">$$\\text{then,} \\;\\;\\; \\lambda_1 \\leq C_n(x,y) \\leq\\lambda_2$$\n",
    ">\n",
    ">* **$\\text{A}$**: Structure Tensor\n",
    ">* **No structure**(smooth): $\\lambda_1 \\approx \\lambda_2 \\approx 0$\n",
    ">* **1D structure**(edge): $\\lambda_1 \\approx 0$ (direction of edge), $\\lambda_2$ is large (normal to edge)\n",
    ">* **2D structure**(corner): $\\lambda_1$ and $\\lambda_2$ both large and distinct\n",
    "\n",
    "* **Step 4. If $M_c$ exceeds some threshold $\\rightarrow$ Mark corners**\n",
    "\n",
    ">$$M_c=\\lambda_1 \\lambda_2-\\kappa(\\lambda_1+\\lambda_2)^2$$\n",
    ">$$\\;$$\n",
    ">$$M_c=\\det{\\text{A}} - \\kappa \\text{ tr A}$$\n",
    ">* The second form is preferable (low computational cost)\n",
    ">* $\\kappa$: generally range from $0.04$ to $0.15$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Blob Detection\n",
    "\n",
    "* **Blob:** Area of uniform intensity in the image\n",
    "\n",
    ">* Blobs are usually found inside of objects (as opposed to edges)\n",
    ">* Thus they are less likely to contain background in queries\n",
    ">* +) stability, repeatability, definite optimal scale, ...\n",
    "\n",
    "* **Method 1: Laplacian of Gaussian**\n",
    "\n",
    ">* Convolve with the **Laplacian of Gaussian** $\\rightarrow$ Locate minimum\n",
    ">* As $\\sigma$ increases, larger image features are detected\n",
    "\n",
    "* **Method 2: Difference of Gaussians**\n",
    "\n",
    ">* Use DoG response to approximate the Laplacian of Gaussian (high $\\sigma$ - small $\\sigma$)\n",
    ">* **Scale space pyramid** $\\rightarrow$ subtract one member from the one directly above it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Scale Space\n",
    "* Achieve scale independence by looking at different resolutions\n",
    "* **Scale Space**\n",
    "\n",
    ">\\begin{align}\n",
    "L(x,y,t)&=G(x,y,t)*I(x,y)\\\\\n",
    "\\;\\\\\n",
    "G(x,y,t)&=\\frac{1}{2\\pi t}\\exp{-\\frac{x^2+y^2}{2t}}\\\\\n",
    "\\;\\\\\n",
    "t&=\\sigma^2\n",
    "\\end{align}\n",
    "\n",
    "* **Choose discrete set of low-pass filter**\n",
    "\n",
    ">$$\\sigma_i=2^\\frac{1}{s}\\sigma_{i-1}=2^\\frac{i}{s}\\sigma_0$$\n",
    ">\n",
    ">* $\\sigma$ doubles after $s$ intervals ($=$ an **octave**)\n",
    ">* Avoid blurring with large scales by **subsampling** the image after each octave\n",
    ">* $\\Rightarrow$ **Image Pyramid**\n",
    "\n",
    "* **Within each octave, convolve repeatedly**\n",
    "\n",
    ">$$G(\\sigma_1)*G(\\sigma_2)=G\\left(\\sqrt{\\sigma^2_1+\\sigma^2_2}\\right)$$\n",
    ">\n",
    ">* The following should be satisfied:\n",
    ">\n",
    ">$$G(\\sigma_{i+1})=G(\\sigma_i)*G(\\sigma_k)$$\n",
    ">\n",
    ">* $\\sigma_k$ can be calculated\n",
    ">\n",
    ">\\begin{align}\n",
    "\\sigma_k&=\\sqrt{\\sigma_{i+1}^2-\\sigma_i^2}\\\\\n",
    "\\sigma_{i+1}&=2^{\\frac{1}{s}}\\sigma_i\\\\\n",
    "\\sigma_k&=\\sigma_i\\sqrt{2^{\\frac{2}{s}}-1}\n",
    "\\end{align}\n",
    "\n",
    "* **Ideal scale for a keypoint is located at the maximum of the scale space**\n",
    "  * $\\Rightarrow$ The largest value of the samples in the pyramid is obtained and interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Matching Image Patches\n",
    "\n",
    "* **Normalised Cross-Correlation** between an image patch $P(x,y)$ and other image portion $I(x,y)$\n",
    "\n",
    ">$$c(x,y)=\\frac{\\sum^n_{u=-n}\\sum^n_{v=-n}P(u,v)I(x+u,y+v)}{\\sqrt{\\sum^n_{u=-n}\\sum^n_{v=-n}P^2(u,v)\\sum^n_{u=-n}\\sum^n_{v=-n}I^2(x+u,y+v)}}$$\n",
    "\n",
    "* **Matching intensity patches**\n",
    "\n",
    ">$$CC(P_1, P_2)=\\sum_i^N{P_1[i]P_2[i]}$$\n",
    ">\n",
    ">* Not robust to changes (brightness & contrast)\n",
    "\n",
    "* **Zero Normalised Patches**\n",
    "\n",
    ">$$ZN(x,y)=\\frac{Z(x,y)}{\\sigma}=\\frac{I(x,y)-\\mu}{\\sigma}$$\n",
    ">\n",
    ">* Robust to changes\n",
    ">* Patches can be matched using simple cross-correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. SIFT(Scale Invariant Feature Transform)\n",
    "\n",
    "* **SIFT Keypoint Detection**\n",
    "\n",
    ">* **Step 1:** Obtain DoG images across different scales\n",
    ">  * If the image pyramid is available $\\rightarrow$ subtract an image from the one above it\n",
    ">* **Step 2:** Compare each pixel to its neighbours (in the same and neighbouring scales) to find local extrema\n",
    ">* **Step 3:** Discard the candidates with low-contrast (sensitive to noise)\n",
    ">* **Step 4:** Discard the candidates on the edges (sensitive to background image)\n",
    ">* **Step 5:** Calculate the orientations of the candidates from the direction of the intensity gradient\n",
    "\n",
    "* **SIFT Interest Point Descriptor**\n",
    "\n",
    ">* **Step 1:** Extract a $N \\times N$ patch at the given keypoint (typically $N=16$)\n",
    ">  * Area of patch: selected in accordance with the scale of the keypoint\n",
    ">* **Step 2:** Calculate the intensity gradient in each pixel\n",
    ">* **Step 3:** Divide the patch into $c$ cells (typically $c=16$)\n",
    ">* **Step 4:** Within each cell, bin the intensity gradients into $d$ directions\n",
    ">  * In this process, the gradients are weighted by the Gaussian window of $\\sigma$\n",
    ">  * $\\Rightarrow$ robustness to occlusion / $\\sigma$: half the scale of the interest point\n",
    ">* **Step 5:** Normalise the resulting $(d \\times c)$-dim vector\n",
    ">  * $\\Rightarrow$ robustness to affine lighting changes (e.g. brightness and contrast)\n",
    ">* **Step 6:** Apply threshold of $0.2$ and re-normalise\n",
    ">  * $\\Rightarrow$ robustness to non-affine lighting changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Texture\n",
    "* **What is Texture?**\n",
    "\n",
    ">* **Image Texture** consists of organised patterns of regular sub-elements called **textons**\n",
    "\n",
    "* **Characterising Texture**\n",
    "\n",
    ">* **Filter bank**:\n",
    ">  * $8$ Lablacian of Gaussian filters\n",
    ">  * $4$ Gaussian filters at different scales\n",
    ">  * $36$ Oriented filters\n",
    ">    * $6$ Different angles\n",
    ">    * $3$ Different scales\n",
    ">    * $2$ Different phases ($1^{st} \\text{&}\\; 2^{nd}$ derivatives of Gaussians on the minor axis)\n",
    ">* **Descriptor**:\n",
    ">  * Simply the concatenated responses of all the filters at a pixel\n",
    ">  * This is innately immune to most changes in an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10. Implementation Details\n",
    "* **Convolution as Truncated Summations**\n",
    "\n",
    ">$$S(x,y)=\\sum_{u=-n}^{n} \\sum_{v=-n}^{n} G_\\sigma(u,v)I(x-u,y-v)$$\n",
    ">\n",
    ">* Kernels are trucated so that the discarded samples are less than $1/1000$ of the peak value\n",
    ">* $\\pm 3\\sigma$ is often enough / smaller $n$ leads to sharp discontinuity\n",
    "\n",
    "* **2D Convolution $\\rightarrow$ Two 1D Convolutions**\n",
    "\n",
    ">$$G_\\sigma(x,y)*I(x,y)=g_\\sigma(x)*[g_\\sigma(y)*I(x,y)]$$\n",
    ">\n",
    ">$$\\mathcal{O} \\left((2n+1)^2 \\right) \\text{ vs. } \\mathcal{O} \\left(2(2n+1)\\right)$$\n",
    "\n",
    "* **Differentiation** (approximation using **Taylor Expansion**)\n",
    "\n",
    ">$$\\frac{\\partial S}{\\partial x} \\approx \\frac{S(x+1,y)-S(x-1,y)}{2}$$\n",
    ">\n",
    ">* Equivalent to convolving the rows of image samples with the kernel $(1/2, 0, -1/2)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
