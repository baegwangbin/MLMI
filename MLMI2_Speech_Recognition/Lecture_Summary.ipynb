{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    ">## 1. Introduction\n",
    "\n",
    ">## 2. Speech Signal Processing - Spectral Analysis\n",
    "\n",
    ">## 3. Speech Signal Processing - Linear Prediction and Cepstral Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. The Speech Waveform\n",
    "\n",
    "><img src=\"images/image01.png\" width=700>\n",
    "\n",
    "* **The waveform is**:\n",
    "\n",
    ">1. **Non-stationary** \n",
    ">2. Mixture of **pseudo-periodic** $+$ **random** components\n",
    "\n",
    "* **Human speech production mechanism**:\n",
    "\n",
    ">1. **Acoustic tube**: variably-shaped / responsible for detailed sounds\n",
    ">2. **Excitation source**: responsible for broad distinctions in speech sound\n",
    ">  1. **Voiced sounds** $\\leftarrow$ Vocal cords which vibrate when air from the lungs is forced through them\n",
    ">  2. **Fricative sounds** $\\leftarrow$ Turbulence caused by forcing air through constrictions formed by raising the tongue to narrow the acoustic tube\n",
    ">  3. **Plosive sounds** $\\leftarrow$ Turbulence caused by the release of air following a complete closure of the acoustic tube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Speech: Sequence of Phones\n",
    "* **Speech**: Sequence of sounds called **phones**\n",
    "* **Phones**: Directly associated with basic units of speech - **phonemes**\n",
    "* **ARPAbet**: American English phone set\n",
    "\n",
    ">* **Consonant Classification**\n",
    ">  * 5 classes based on the type of vocal tract constriction\n",
    ">  * $\\Rightarrow$ plosive(stops), fricatives, affricates, liquids(semi-vowels), nasals\n",
    ">* **Vowel Classification**\n",
    ">  * Based on **tongue position** (front to back) & **jaw position** (low to high)\n",
    ">  * $\\Rightarrow$ Represented by **vowel quadrilateral** (**Diphthongs**: arrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. ASR: Automatic Speech Recognition\n",
    "* **ASR**\n",
    "\n",
    ">$$\\text{Changing time signal} \\rightarrow \\text{Corresponding symbol sequence}\\;(\\textbf{string of words})$$\n",
    ">* We need a **sequence-to-sequence** model\n",
    ">* This is **NOT** about understanding the input\n",
    "\n",
    "* **Several Styles of ASR**\n",
    "\n",
    ">||Input Mode|Vocab Size|Basic Unit|Grammar|\n",
    "|-|-|-|-|-|\n",
    "|**Isolated**|discrete|small|word|none|\n",
    "|**Continuous**|continuous|medium|phone|FS/N-gram|\n",
    "|**Discrete large vocab**|discrete|large|phone|N-gram|\n",
    "|**Continuous large vocab**|continuous|large|phone|N-gram|\n",
    "\n",
    "* **Performance-metric for ASR**\n",
    "\n",
    ">* **WER(Word Error Rate)** for isolated word recognition\n",
    ">$$\\text{%WER}=100\\times\\frac{N(\\text{correct})}{N(\\text{reference})}$$\n",
    ">$$\\;$$\n",
    ">* **WER** for continuous speech recognition\n",
    ">$$\\text{%WER}=100\\times\\frac{N(\\text{ins.})+N(\\text{del.})+N(\\text{sub.})}{N(\\text{reference})}$$\n",
    "\n",
    ">* **User Satisfaction**\n",
    "\n",
    "* **The performance of ASR is affected by**\n",
    "\n",
    ">* **Inter-speaker variability** (important to develop **recognizer robustness**)\n",
    ">* **Intra-speaker variability** (e.g. situation, aging, ...)\n",
    ">* **Microphone** (close vs far / fixed vs variable / bandwidth)\n",
    ">* **Background noise** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Recognition Model Architecture\n",
    "* **Feature Extraction**\n",
    "\n",
    ">* Normally) use a **fixed duration** of speech signal (**frame**)\n",
    ">* Each frame corresponds to a **feature vector**\n",
    ">* Spectral information is often encoded as a **cepstral representation** (e.g. MFCCs)\n",
    "\n",
    "* **Generative model approach**\n",
    "\n",
    ">$$\\widehat{W}=\\argmax_W{P(\\textbf{O}|W)P(W)}$$\n",
    ">* $\\textbf{O}$: Stream of feature vectors describing the utterance\n",
    ">* $P(\\textbf{O}|W)$: given by acoustic model\n",
    ">* $P(W)$: given by language model\n",
    "\n",
    "* **Hidden Markov Model (HMM)**\n",
    "\n",
    ">* **GMM-HMM**: uses Gaussian Mixture Models\n",
    ">* **DNN-HMM**: uses Deep Neural Networks\n",
    "\n",
    "* **General Recognition Architecture**\n",
    "\n",
    "><img src=\"images/image02.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spectral Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Quasi-Stationarity\n",
    "* **Assumption**: speech is stationary over a **short interval**\n",
    "  * Normally $10\\;\\text{~}\\;20\\;\\text{ms}$\n",
    "  * Too short $\\rightarrow$ insufficient time to determine properties\n",
    "  * Too long $\\rightarrow$ approximation becomes invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Digital Signals\n",
    "\n",
    ">$$\\text{Analog} \\rightarrow \\text{Digital}$$\n",
    ">\n",
    ">* **Step 1: Low-pass filter** (remove $f>0.5\\;f_{sampling}$: **Nyquist's theorem**)\n",
    ">* **Step 2: Sampling** (discretisation in time)\n",
    ">  * High Quality: $16\\text{kHz}$ / Normal Quality: $8\\text{kHz}$\n",
    ">* **Step 3: ADC** (discretisation in amplitude)\n",
    ">  * High Quality: $16\\text{bits/sample}$ / Normal Quality: $8\\text{bits/sample}$\n",
    ">  * Output ranges from $-2^{Q-1}, ... , 2^{Q-1}-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Windowing\n",
    "* DFT assumes periodicity $\\rightarrow$ **Discontinuity** $\\rightarrow$ Undesired high-frequency\n",
    "\n",
    "><img src=\"images/image03.png\", width=400>\n",
    "\n",
    "* **Hamming Window**\n",
    "  * Attenuates the discontinuity **but** also smears the spectral peaks\n",
    "\n",
    ">$$w(nT)=0.54-0.46\\cos{ \\left[ \\frac{2\\pi n}{N-1} \\right] }$$\n",
    "\n",
    "* **Block Processing**\n",
    "  * Allow overlap between windows\n",
    "  * Typically) Frame: $10\\text{ms}$ & Windows: $25\\text{ms}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Fourier Transform\n",
    "* **Fourier Analysis**\n",
    "\n",
    ">* **Periodic Signal of $f_0$**: constructed by sinusoids of $f_0, 2f_0, 3f_0, ...$\n",
    "\n",
    ">  * $f_0$: fundamental frequency\n",
    ">  * $nf_0 (n>1)$: harmonics\n",
    "\n",
    ">* **Aperiodic & Stochastic Signal**: spectram which is a continuous function of frequency\n",
    "\n",
    "* **Fourier Transform**\n",
    "\n",
    "><img src=\"images/image04.png\", width=500>\n",
    "\n",
    "* **FFT - Fast Fourier Transform**\n",
    "\n",
    ">$$\\mathcal{O}(N^2) \\rightarrow \\mathcal{O}(N\\log N)$$\n",
    ">\n",
    ">* Makes use of the symmetry\n",
    ">* Requires the window to be a power of 2 samples in size\n",
    ">* This can be achieved by appropriate choice of analysis size and/or zero-padding (after windowing) the frame to a power of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. DFT - Discrete Fourier Transform\n",
    "* **Cosine Correlation**\n",
    "\n",
    ">$$c(\\Omega)=\\sum^{N-1}_{n=0}{s(nT)\\cos{\\left(\\frac{2\\pi np}{N}\\right)}}\\;\\;\\;,\\;\\;\\;p=0,1,...,N-1$$\n",
    "\n",
    "* **Sine Correlation**\n",
    "\n",
    ">$$s(\\Omega)=\\sum^{N-1}_{n=0}{s(nT)\\sin{\\left(\\frac{2\\pi np}{N}\\right)}}\\;\\;\\;,\\;\\;\\;p=0,1,...,N-1$$\n",
    "\n",
    "* **Amplitude**\n",
    "\n",
    ">$$a_p=\\sqrt{c^2(\\Omega)+s^2(\\Omega)}$$\n",
    "\n",
    "* **Phase**\n",
    "\n",
    ">$$\\phi_p=\\tan^{-1}\\left[\\frac{s(\\Omega)}{c(\\Omega)}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Complex Formulation of DFT\n",
    "\n",
    "\n",
    "* **DFT**\n",
    "\n",
    ">\\begin{align}\n",
    "S_p&=\\sum^{N-1}_{n=0}{s(nT)\\left[\\cos{\\left(\\frac{2\\pi np}{N}\\right)}-j\\sin{\\left(\\frac{2\\pi np}{N}\\right)}\\right]}\\\\\n",
    "&=\\sum^{N-1}_{n=0}{s(nT) e^{-j\\left(\\frac{2\\pi np}{N}\\right)}}\\;\\;\\;,\\;\\;\\;p=0,1,...,N-1$$\n",
    "\\end{align}\n",
    "\n",
    "* **Inverse DFT**\n",
    "\n",
    ">$$s(nT)=\\frac{1}{N}\\sum^{N-1}_{p=0}{S_p e^{j\\left(\\frac{2\\pi np}{N}\\right)}}\\;\\;\\;,\\;\\;\\;n=0,1,...,N-1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Spectral Properties of Speech\n",
    "\n",
    "* **Vowel** (iy)\n",
    "\n",
    "><img src=\"images/image05.png\", width=400>\n",
    ">\n",
    ">* **Time domain**: approximately **periodic** with $f_0=130\\text{Hz}$\n",
    ">* **Frequency domain**: corresponding periodic excitation $(\\text{~}7.5\\;\\text{cycles/1000Hz})$\n",
    "\n",
    "* **Fricative** (s)\n",
    "\n",
    "><img src=\"images/image06.png\", width=400>\n",
    ">\n",
    ">* **Time domain**: no periodicity\n",
    ">* **Frequency domain**: random variations at much higher frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Spectral Features of Sounds\n",
    "\n",
    "* **Vowel**\n",
    "\n",
    ">* Characterised by the first 3 **formants**\n",
    ">* Following is a simple relationship\n",
    "\n",
    ">||Tongue Front|Tongue Back|\n",
    "|-|-|-|\n",
    "|High Jaw|$F_1$ Low, $F_2$ High|$F_1$ Low, $F_2$ Low|\n",
    "|Low Jaw|$F_1$ High, $F_2$ High|$F_1$ High, $F_2$ Low|\n",
    "\n",
    "* **Liquids**\n",
    "\n",
    ">* Characterised by formant position & dynamics\n",
    ">* Overall energy is lower than for vowels\n",
    "\n",
    "* **Nasals**\n",
    "\n",
    ">* Strong low $F_1$ around $250\\text{Hz}$ and weak higher formants\n",
    ">* Often energy around $2.5\\text{kHz}$\n",
    "\n",
    "* **Fricatives**\n",
    "\n",
    ">* Most energy in higher frequencies\n",
    ">* Voiced fricatives show weak formant structure\n",
    "\n",
    "* **Stops**\n",
    "\n",
    ">* Characterised by silence,\n",
    ">* optionally followed by a burst of high energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Spectrograms\n",
    "* Dimensions: **time & frequency**\n",
    "* Intensity of image: **spectral energy**\n",
    "\n",
    "><img src=\"images/image07.png\", width=400>\n",
    ">\n",
    ">||Short window|Wide window|\n",
    "|-|-|-|\n",
    "|Time resolution|Good|Poor|\n",
    "|Frequency resolution|Poor|Good|\n",
    "||Vertical lines|Horizontal lines|\n",
    "|Band|Wide|Narrow|\n",
    "||(pitch periods visible)|(harmonics of $f_0$ visible)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Prediction and Cepstral Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
