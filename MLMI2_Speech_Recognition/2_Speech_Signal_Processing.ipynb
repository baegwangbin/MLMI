{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spectral Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Quasi-Stationarity Assumption\n",
    "* Speech is stationary over a **short interval** $(10\\;\\text{~}\\;20\\;\\text{ms})$ $\\rightarrow$ find the signal characteristics in each interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Digital Signals\n",
    "\n",
    ">$$\\text{Analog} \\rightarrow \\text{Digital}$$\n",
    ">\n",
    ">* **Step 1: Low-pass filter** (remove $f>0.5\\;f_{sampling}$: **Nyquist's theorem**)\n",
    ">* **Step 2: Sampling** (discretisation in time)\n",
    ">  * High Quality: $16\\text{kHz}$ vs. Normal Quality: $8\\text{kHz}$\n",
    ">* **Step 3: ADC** (discretisation in amplitude)\n",
    ">  * High Quality: $16\\text{bits/sample}$ vs. Normal Quality: $8\\text{bits/sample}$\n",
    ">  * Output ranges from $-2^{Q-1}, ... , 2^{Q-1}-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Windowing\n",
    "* DFT assumes periodicity $\\rightarrow$ **Discontinuity** $\\rightarrow$ Undesired high frequency\n",
    "* **Hamming Window**\n",
    "  * Attenuates the discontinuity **but** also smears the spectral peaks\n",
    "\n",
    ">$$w(nT)=0.54-0.46\\cos{ \\left[ \\frac{2\\pi n}{N-1} \\right] }$$\n",
    "\n",
    "* **Block Processing**\n",
    "  * Allow overlap between windows\n",
    "  * Typically) Frame: $10\\text{ms}$ & Windows: $25\\text{ms}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Fourier Transform\n",
    "* **Fourier Analysis**\n",
    "\n",
    ">* **Periodic Signal of $f_0$**: constructed by sinusoids of $f_0, 2f_0, 3f_0, ...$\n",
    "\n",
    ">  * $f_0$: fundamental frequency\n",
    ">  * $nf_0 (n>1)$: harmonics\n",
    "\n",
    ">* **Aperiodic & Stochastic Signal**: spectrum which is a continuous function of frequency\n",
    "\n",
    "* **Fourier Transform**\n",
    "\n",
    "><img src=\"images/image04.png\" width=500>\n",
    "\n",
    "* **FFT - Fast Fourier Transform**\n",
    "\n",
    ">$$\\mathcal{O}(N^2) \\rightarrow \\mathcal{O}(N\\log N)$$\n",
    ">\n",
    ">* Makes use of the symmetry\n",
    ">* Requires the window to be a power of 2 samples in size\n",
    ">* This can be achieved by appropriate choice of analysis size and/or zero-padding (after windowing) the frame to a power of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. DFT - Discrete Fourier Transform\n",
    "* **Cosine Correlation**\n",
    "\n",
    ">$$c(\\Omega)=\\sum^{N-1}_{n=0}{s(nT)\\cos{\\left(\\frac{2\\pi np}{N}\\right)}}\\;\\;\\;,\\;\\;\\;p=0,1,...,N-1$$\n",
    "\n",
    "* **Sine Correlation**\n",
    "\n",
    ">$$s(\\Omega)=\\sum^{N-1}_{n=0}{s(nT)\\sin{\\left(\\frac{2\\pi np}{N}\\right)}}\\;\\;\\;,\\;\\;\\;p=0,1,...,N-1$$\n",
    "\n",
    "* **Amplitude**\n",
    "\n",
    ">$$a_p=\\sqrt{c^2(\\Omega)+s^2(\\Omega)}$$\n",
    "\n",
    "* **Phase**\n",
    "\n",
    ">$$\\phi_p=\\tan^{-1}\\left[\\frac{s(\\Omega)}{c(\\Omega)}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Complex Formulation of DFT\n",
    "\n",
    "\n",
    "* **DFT**\n",
    "\n",
    ">\\begin{align}\n",
    "S_p&=\\sum^{N-1}_{n=0}{s(nT)\\left[\\cos{\\left(\\frac{2\\pi np}{N}\\right)}-j\\sin{\\left(\\frac{2\\pi np}{N}\\right)}\\right]}\\\\\n",
    "&=\\sum^{N-1}_{n=0}{s(nT) e^{-j\\left(\\frac{2\\pi np}{N}\\right)}}\\;\\;\\;,\\;\\;\\;p=0,1,...,N-1\n",
    "\\end{align}\n",
    "\n",
    "* **Inverse DFT**\n",
    "\n",
    ">$$s(nT)=\\frac{1}{N}\\sum^{N-1}_{p=0}{S_p e^{j\\left(\\frac{2\\pi np}{N}\\right)}}\\;\\;\\;,\\;\\;\\;n=0,1,...,N-1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Spectral Properties of Speech\n",
    "\n",
    "* **Vowel** (iy)\n",
    "\n",
    "><img src=\"images/image05.png\" width=400>\n",
    ">\n",
    ">* **Time domain**: approximately **periodic** with $f_0=130\\text{Hz}$\n",
    ">* **Frequency domain**: corresponding periodic excitation $(\\text{~}7.5\\;\\text{cycles/1000Hz})$\n",
    "\n",
    "* **Fricative** (s)\n",
    "\n",
    "><img src=\"images/image06.png\" width=400>\n",
    ">\n",
    ">* **Time domain**: no periodicity\n",
    ">* **Frequency domain**: random variations at much higher frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Spectral Features of Sounds\n",
    "\n",
    "* **Vowel**\n",
    "\n",
    ">* Characterised by the first 3 **formants**\n",
    ">* Following is a simple relationship\n",
    "\n",
    ">||Tongue Front|Tongue Back|\n",
    "|-|-|-|\n",
    "|**High Jaw**|$F_1$ Low, $F_2$ High|$F_1$ Low, $F_2$ Low|\n",
    "|**Low Jaw**|$F_1$ High, $F_2$ High|$F_1$ High, $F_2$ Low|\n",
    "\n",
    "* **Liquids**\n",
    "\n",
    ">* Characterised by formant position & dynamics\n",
    ">* Overall energy is lower than for vowels\n",
    "\n",
    "* **Nasals**\n",
    "\n",
    ">* Strong low $F_1$ around $250\\text{Hz}$ and weak higher formants\n",
    ">* Often energy around $2.5\\text{kHz}$\n",
    "\n",
    "* **Fricatives**\n",
    "\n",
    ">* Most energy in higher frequencies\n",
    ">* Voiced fricatives show weak formant structure\n",
    "\n",
    "* **Stops**\n",
    "\n",
    ">* Characterised by silence,\n",
    ">* Optionally followed by a burst of high energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9. Spectrograms\n",
    "* Dimensions: **time & frequency**\n",
    "* Intensity of image: **spectral energy**\n",
    "\n",
    "><img src=\"images/image07.png\" width=400>\n",
    ">\n",
    ">||Short window|Wide window|\n",
    "|-|-|-|\n",
    "|Time resolution|Good|Poor|\n",
    "|Frequency resolution|Poor|Good|\n",
    "||(vertical lines)|(horizontal lines)|\n",
    "|Band|Wide|Narrow|\n",
    "||(pitch periods visible)|(harmonics of $f_0$ visible)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear Prediction and Cepstral Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Source-Filter Model\n",
    "\n",
    "* **Basic Idea**\n",
    "\n",
    ">$$\\underset{\\text{(vocal cords)}}{\\textbf{Sound Source}} \\;\\; + \\;\\; \\underset{\\text{(vocal tract)}}{\\textbf{Linear Acoustic Filter}}$$\n",
    ">\n",
    ">* **Linear Prediction Analysis:** method to explicitly determine the parameters of the source-filter model\n",
    ">* When used for **speech synthesis:** filter parameters are updated every $\\text{~10ms}$\n",
    ">* When used for **speech analysis:** speech is divided into segments $(\\text{10~25ms})$\n",
    "\n",
    "* **Assumptions**\n",
    "\n",
    ">1. **Sound source (excitation):** periodic pulse train or noise\n",
    ">2. **Filter:** single lossless linear time variant filter with single input\n",
    ">3. The filter and excitation characteristics are stationary over $\\text{~}10\\text{ms}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. General Linear Constant Coefficient Difference Equation\n",
    "\n",
    "* **General Eq. may include any no. of past inputs & outputs**\n",
    "\n",
    ">$$y[nT]=\\sum^p_{i=1}a_iy\\left[(n-i)T\\right]+\\sum^q_{i=0}b_ix\\left[(n-i)T\\right]$$\n",
    "\n",
    "* **Taking Z-transforms**\n",
    "\n",
    ">$$Y(z)=Y(z)\\sum^p_{i=1}a_iz^{-i} + X(z)\\sum^q_{i=0}b_iz^{-i}$$\n",
    "\n",
    ">$$H(z)=\\frac{Y(z)}{X(z)}=\\frac{\\sum^q_{i=0}b_iz^{-i}}{1-\\sum^p_{i=1}a_iz^{-i}}$$\n",
    "\n",
    ">$$p=\\text{no. of poles} \\;\\;\\;,\\;\\;\\; q=\\text{no. of zeros}$$\n",
    "\n",
    ">* $p=0$: **non-recursive** or **FIR**(finite impulse response)\n",
    ">* $p>0$: **recursive** or **IIR**(infinite impulse response)\n",
    ">* $q=0,p>0$: **all-pole filter**\n",
    "\n",
    "* **Two-Pole Resonators**\n",
    "  * Used to **model a single formant** of a particular bandwidth and frequency\n",
    "  * Can be used in series or parallel to create more complex filters\n",
    "\n",
    ">$$H(z)=\\frac{1}{1-bz^{-1}-cz^{-2}}$$\n",
    ">\n",
    ">* $c$: always less than 1 for a **stable** filter and the values of $b$, $c$ determine the frequency and bandwidth of the resonator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Linear Prediction\n",
    "\n",
    "* **Linear Prediction**\n",
    "  * **Idea:** each sample can be predicted as a weighted sum of the $p$ preceding samples\n",
    "\n",
    ">$$\\hat{s}[n]=\\sum^p_{i=1}a_is[n-i]$$\n",
    ">* $s[n]\\equiv s[nT]$\n",
    "\n",
    "* **Prediction Error**\n",
    "\n",
    ">$$e[n]=s[n]-\\hat{s}[n]=s[n]-\\sum^p_{i=1}a_is[n-i]$$\n",
    "\n",
    "* **Taking Z-transforms**\n",
    "\n",
    ">$$E[z]=\\left[ 1-\\sum^p_{i=1}a_iz^{-i} \\right] S(z)$$\n",
    "\n",
    "* **Filter Transfer Function**\n",
    "\n",
    ">$$H[z]=\\frac{S(z)}{E(z)}=\\frac{1}{1-\\sum^p_{i=1}a_iz^{-i}}$$\n",
    ">* **All-pole** digital filter, with prediction error signal as input\n",
    "\n",
    "* **Source Filter Model**\n",
    "  * Assume that the input is spectrally flat $\\rightarrow$ $E(z)=G$\n",
    "  \n",
    ">$$H[z]=\\frac{G}{1-\\sum^p_{i=1}a_iz^{-i}}=\\frac{G}{A(z)}$$\n",
    ">* $G$: estimated to match the overall energy\n",
    ">* $1/A(z)$: models the spectral shape of the vocal tract (also glottal source shaping)\n",
    ">* Error sequence: models the excitation\n",
    "\n",
    "* **Calculating the LP Coefficients $\\Rightarrow$ Normal Equations**\n",
    "\n",
    ">$$E_p=\\sum_n e[n]^2=\\sum_n \\left( s[n] - \\sum^p_{k=1}a_ks[n-k] \\right)^2$$\n",
    "\n",
    ">$$\\frac{\\partial E_p}{\\partial a_k}=0 \\;\\;\\;\\Rightarrow\\;\\;\\; \\sum_n s[n]s[n-k]=\\sum^p_{i=1}a_i\\sum_ns[n-i]s[n-k]\\;\\;\\;,\\;\\;\\;k=1,...,p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Autocorrelation Method\n",
    "\n",
    "* **Autocorrelation Sequence** $r_{i-k}$\n",
    "\n",
    ">$$\\sum^\\infty_{n=-\\infty} s[n-i]s[n-k] = \\sum^\\infty_{n=-\\infty} s[n]s[n+i-k]$$\n",
    "\n",
    "* **Normal Equations**\n",
    "\n",
    ">$$r_k=\\sum^p_{i=1}a_ir_{i-k}\\;\\;\\;,\\;\\;\\;k=1,...,p$$\n",
    ">* For $N$ sample window,\n",
    ">$$r_k=\\sum^{N-k-1}_{n=0}s[n]s[n+k]$$\n",
    "\n",
    "* **Durbin's Algorithm**\n",
    "\n",
    ">\\begin{align}\n",
    "k_i &= \\left( r_i - \\sum^{i-1}_{j-1}a_j^{(i-1)}r_{i-j} \\right) / E_p^{(i-1)} \\\\\n",
    "a^{(i)}_i &= k_i \\\\\n",
    "a^{(i)}_j &= a^{(i-1)}_j-k_ia^{(i)}_{i-j} \\;\\;\\;,\\;\\;\\; 1 \\leq j < i \\\\\n",
    "E^{(i)}_p &= (1-k^2_i)E_p^{(i-1)} \\\\\n",
    "A_i &= \\left[ \\frac{1-k_i}{1+k_i} \\right] A_{i-1}\n",
    "\\end{align}\n",
    "\n",
    ">* $a_k^{(i)}$: LP parameters at iteration $i$\n",
    ">* $E_p^{(i)}$: Sum-squared predictor error $(e^{(0)}_p=r_0) \\rightarrow$ guaranteed to decrease\n",
    ">* $k_i$: reflection coefficients $(|k_i|<1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Inverse Filtering\n",
    "* **Inverse Filtering:** finding the error signal or prediction residual\n",
    "* Example: the residual signal for a vowel waveform:\n",
    "\n",
    "><img src=\"images/image08.png\" width=400>\n",
    "\n",
    ">* Most short term correlations seem to be lost in the error signal\n",
    ">* The residual contains long term correlations due to pitch pulses\n",
    ">* There is a spike at the pitch periods when prediction is poor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. LP Spectrum\n",
    "\n",
    "* **LP Spectrum**\n",
    "\n",
    ">* Frequency response of the **Linear Prediction Filter** $H(z)$: smoothed approximation of the speech spectrum\n",
    ">* Evaluate using:\n",
    ">  * **Direct substitution**: set $z=e^{i\\omega T}$ and computer magnitude\n",
    ">  * **DFT/FFT**: Construct the N-point impulse response for the inverse filter $A(z)$, zero-pad and find frequency response, invert and scale for $H(z)$\n",
    "\n",
    "* **Applications of Linear Prediction**\n",
    "\n",
    ">* **1. Pitch Extraction**\n",
    ">* **2. Formant Analysis**\n",
    ">* **3. Speech Synthesis/Coding**\n",
    ">* **4. Speech Recognition Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7. Cepstral Analysis\n",
    "\n",
    "* **Aim**\n",
    "\n",
    ">$$\\text{Signal Spectrum} \\rightarrow \\text{Excitation} \\times \\text{Vocal Tract} \\times \\text{Other Filtering Effects}$$\n",
    "\n",
    "* **Homomorphic Filtering**\n",
    "\n",
    "><img src=\"images/image09.png\" width=400>\n",
    "\n",
    "* **Cepstrum**\n",
    "\n",
    "><img src=\"images/image10.png\" width=400>\n",
    "\n",
    ">* For real cepstrum, the log is applied to the magnitude spectrum\n",
    ">* In the cepstrum, vocal tract impulse response decays rapidly and can be separated (by windowing) from the excitation\n",
    ">* The cepstrum is computed in the **quefrency** domain and filtering in this domain is called **liftering**\n",
    ">* Note that taking the IDFT of the cepstrum doesn't return to the time domain because of the non-linear log operation\n",
    "\n",
    "><img src=\"images/image11.png\" width=400>\n",
    "\n",
    ">* Making $h$ smaller increases the smoothing over the whole spectrum\n",
    "\n",
    "* **Applications of Cepstral Analysis**\n",
    "\n",
    ">* **1. Pitch Estimation**\n",
    ">* **2. Smoothed Spectrum**\n",
    ">* **3. Speech Coding**\n",
    ">* **4. Recognition**\n",
    "\n",
    "* **Mel-Scale Filterbanks**\n",
    "  * The energy in each frequency band is computed from the DFT\n",
    "\n",
    "><img src=\"images/image12.png\" width=300>\n",
    "\n",
    ">$$\\textbf{Mel-scale:}\\;\\;\\;\\text{Mel}(f)=2595\\log_10{\\left(1+\\frac{f}{700}\\right)}$$\n",
    "\n",
    "><img src=\"images/image13.png\" width=300>\n",
    "\n",
    "* **Discrete Cosine Transform**\n",
    "  * Simplified version of DFT\n",
    "  * Uses the fact that the log magnitude spectrum is real-valued, symmetric w.r.t. 0 and periodic in frequency\n",
    "  \n",
    ">$$c_n=\\sqrt{\\frac{2}{p}}\\sum^P_{i=1}m_i\\cos{\\left[ \\frac{n(i-\\frac{1}{2})\\pi}{P} \\right]}$$\n",
    ">\n",
    ">* $P$: no. of filterbank channels\n",
    ">* $c_n$: **MFCCs(Mel-Frequency Cepstral Coefficients)**\n",
    ">* $c_0$: measure of the signal energy\n",
    ">* DCT **decorrelates** the spectral coefficients and allows them to be modelled with diagonal Gaussian distributions\n",
    "\n",
    "* **PLP(Perceptual Linear Prediction)**\n",
    "  * Alternative for MFCC\n",
    "  \n",
    ">* 1. First the power spectrum is computed on a non-linear frequency scale (Bark scale)\n",
    ">* 2. The power is compressed (e.g. with a power-law compression) and other compensation for the frequency sensitivity of human hearing is applied\n",
    ">* 3. Autocorrelation coefficients are obtained from inverse DFT of the power spectrum\n",
    ">* 4. Autocorrelation analysis LPC can be computed using Durbin's algorithm\n",
    ">* 5. Cepstral coefficients are obtained by applying linear prediction to cepstrum recursion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
