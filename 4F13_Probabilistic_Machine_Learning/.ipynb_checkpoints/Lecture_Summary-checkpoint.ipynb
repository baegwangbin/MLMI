{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\usepackage{amsmath}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    ">## 1. Introduction to Probabilistic Machine Learning\n",
    "* 1.1. Mathematical Models\n",
    "* 1.2. Linear in the Parameters Model\n",
    "* 1.3. Likelihood and Noise\n",
    "* 1.4. Probability Basics\n",
    "* 1.5. Bayesian Inference and Prediction in Finite Regression Models\n",
    "\n",
    ">## 2. Gaussian Process\n",
    "* 2.1. Gaussian Distribution\n",
    "* 2.2. Gaussian Process\n",
    "* 2.3. Posterior Gaussian Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to Probabilistic Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Mathematical Models\n",
    "*Essentially, all models are wrong, but some are useful* - George E. T. Box\n",
    "\n",
    "* **Aim to:**\n",
    "\n",
    ">1. Make predictions\n",
    ">2. Generalise from observations (inter/extrapolation)\n",
    ">3. Understand and interpret statistical relationships\n",
    ">4. Generate more data, from a similar distribution\n",
    "\n",
    "* **Originate from:**\n",
    "\n",
    ">1. **First Principles** (e.g. Newtonian mechanics)\n",
    ">2. **Observations** (data)\n",
    ">  * $\\Rightarrow$ ***Machine Learning***: significantly rely on data\n",
    "\n",
    "* **Rely on:**\n",
    "\n",
    ">1. **Knowledge** (expressed through ***priors***)\n",
    ">2. **Assumptions** (e.g. conditional independence)\n",
    ">3. **Simplifying assumptions** (if they are 'good enough')\n",
    "\n",
    "* **Terminology:**\n",
    "\n",
    "><img src=\"images/image01.png\" width=300>\n",
    ">\n",
    ">* $y$: observations\n",
    ">* $x$: unobserved or hidden or latent variables (# grow with data)\n",
    ">* $A$: parameter 1 for transitions\n",
    ">* $C$: parameter 2 for emissions (# fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Linear in the Parameters Regression\n",
    "\n",
    "* **Model**\n",
    "\n",
    ">$$f_w(x)=\\sum^{M}_{j=0}{w_j\\Phi_j(x)} \\;\\;\\; \\text{where} \\;\\;\\; \\Phi_j(x)=x^j$$\n",
    ">\n",
    ">$$\\widehat{y}=\\Phi \\mathbf{w}$$\n",
    "\n",
    "* **Least Squares Fit**\n",
    "\n",
    ">$$\\text{cost:} \\;\\;\\; \\text{E}(\\mathbf{w})=(y-\\widehat{y})^T(y-\\widehat{y})=(y-\\Phi \\mathbf{w})^T(y-\\Phi \\mathbf{w})$$\n",
    "\n",
    ">$$\\frac{\\partial \\text{E}(\\mathbf{w})}{\\partial \\mathbf{w}}=0 \\;\\;\\; \\Rightarrow \\;\\;\\; \\widehat{\\mathbf{w}}=(\\Phi^T\\Phi)^{-1}\\Phi^Ty$$\n",
    "\n",
    "* **Overfitting**\n",
    "\n",
    "><img src=\"images/image02.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Likelihood and Noise\n",
    "\n",
    "><img src=\"images/image03.png\" width=400>\n",
    "\n",
    "* **Gaussian Noise Assumption:**\n",
    "\n",
    ">$$\\boldsymbol{\\epsilon}\\; \\text{~} \\; \\mathcal{N}(\\boldsymbol{\\epsilon}_n;\\textbf{0},\\sigma^2_{noise} \\textbf{I})$$\n",
    "\n",
    "* **Maximum Likelihood Estimate:**\n",
    "\n",
    ">$$p(\\mathbf{y}|\\mathbf{f}, {\\sigma}^2_{noise})=\\mathcal{N}(\\mathbf{y};\n",
    "\\mathbf{f},\\sigma^2_{noise})=\\left( \\frac{1}{\\sqrt{2\\pi \\sigma^2_{noise}}} \\right)^N \\exp{\\left( -\\frac{||\\mathbf{y}-\\mathbf{f}||^2}{2\\sigma^2_{noise}}\\right)}$$\n",
    "\n",
    ">* **ML solution = Least squares solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Probability Basics\n",
    "* **Sum Rule**\n",
    "\n",
    ">$$p(A)=\\sum_B{p(A,B)}\\;\\;\\;\\text{or}\\;\\;\\;p(A)=\\int_B{p(A,B)dB}$$\n",
    "\n",
    "* **Product Rule**\n",
    "\n",
    ">$$p(A,B)=p(A|B)p(B)$$\n",
    "\n",
    "* **Bayes' Rule:**\n",
    "\n",
    ">$$p(A|B)=\\frac{p(A,B)}{p(B)}=\\frac{p(B|A)p(A)}{p(B)}$$\n",
    ">\n",
    ">* $p(A)$: **marginal**\n",
    ">* $p(B|A)$: **conditional**\n",
    ">* $p(A,B)$: **joint**\n",
    ">* If $A$ and $B$ are independent, $p(A,B)=p(A)p(B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Bayesian Inference and Prediction in Finite Regression Models\n",
    "\n",
    "* **Posterior:**\n",
    "\n",
    ">$$p(\\mathbf{w}|\\mathbf{x},\\mathbf{y},\\mathcal{M})=\\frac{p(\\mathbf{w}|\\mathcal{M})p(\\mathbf{y}|\\mathbf{x},\\mathbf{w},\\mathcal{M})}{p(\\mathbf{y}|\\mathbf{x},\\mathcal{M})}=\\mathcal{N}(\\mathbf{w;μ,\\Sigma})$$\n",
    ">$$\\;$$\n",
    ">* **Gaussian Prior**: $p(\\mathbf{w}|\\mathcal{M})=\\mathcal{N}(\\mathbf{w};\\textbf{0},\\sigma^2_\\mathbf{w}\\mathbf{I})$\n",
    ">$$\\;$$\n",
    ">* **Gaussian Likelihood**: $p(\\mathbf{y}|\\mathbf{x},\\mathbf{w},\\mathcal{M})=\\mathcal{N}(\\mathbf{y};\\mathbf{Φw},\\sigma^2_{noise}\\mathbf{I})$\n",
    ">$$\\;$$\n",
    ">* **Marginal Likelihood**: $p(\\mathbf{y}|\\mathbf{x},\\mathcal{M})=\\int{p(\\mathbf{w}|\\mathbf{x},\\mathcal{M})p(\\mathbf{y}|\\mathbf{x},\\mathbf{w},\\mathcal{M})\\text{d}\\mathbf{w}}$\n",
    ">$$\\;$$\n",
    ">$$\\mathbf{μ}=\\left( \\mathbf{Φ}^T\\mathbf{Φ} + \\frac{\\sigma^2_{noise}}{\\sigma^2_{\\mathbf{w}}}\\mathbf{I} \\right)^{-1}\\mathbf{Φ}^T\\mathbf{y} \\;\\;\\;,\\;\\;\\; \\mathbf{Σ}=\\left( \\sigma^{-2}_{noise}\\mathbf{Φ}^T\\mathbf{Φ}+\\sigma^{-2}_{\\mathbf{w}}\\mathbf{I}\\right)^{-1}$$\n",
    "\n",
    "\n",
    "* **Bayesian Inference:**\n",
    "\n",
    ">\\begin{align}\n",
    "p(y_*|x_*,\\mathbf{x},\\mathbf{y},\\mathcal{M})&=\\int{p(y_*,\\mathbf{w}|\\mathbf{x},\\mathbf{y},x_*,\\mathcal{M})\\text{d}\\mathbf{w}}\\\\\n",
    "&= \\int{p(y_*|\\mathbf{w},x_*,\\mathcal{M})p(\\mathbf{w}|\\mathbf{x},\\mathbf{y},\\mathcal{M})\\text{d}\\mathbf{w}}\\\\\n",
    "&=\\mathcal{N}(y_*;\\mathbf{Φ}(x_*)^T\\mathbf{μ},\\mathbf{Φ}(x_*)^T\\mathbf{Σ}\\mathbf{Φ}(x_*)+\\sigma^2_{noise}\\mathbf{I})\n",
    "\\end{align}\n",
    "\n",
    "* **Evidence:** (marginal likelihood, used to select between models)\n",
    "\n",
    ">\\begin{align}\n",
    "p(\\mathcal{M}|\\mathbf{x,y}) \\propto p(\\mathbf{y|\\mathcal{M},x}) &= \\int{p(\\mathbf{w}|\\mathbf{x},\\mathcal{M})p(\\mathbf{y}|\\mathbf{x},\\mathbf{w},\\mathcal{M})\\text{d}\\mathbf{w}}\\\\\n",
    "&=\\mathcal{N}(\\mathbf{y;0,\\sigma^2_{w}ΦΦ}^T+\\sigma^2_{noise}\\mathbf{I})\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gaussian Process\n",
    "\n",
    "* **Basic Idea:**\n",
    "\n",
    ">* In a parametric model, the model is represented using **parameters**\n",
    ">* But, parameters are **nuisance**\n",
    ">* The aim is to work directly in the **space of functions**\n",
    ">  * **Step 1.** Set up a model in terms of parameters\n",
    ">  * **Step 2.** Marginalise out the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Gaussian Distribution\n",
    "\n",
    "* **Univariate:**\n",
    "\n",
    ">$$p(x|\\mu,\\sigma^2)=(2\\pi\\sigma^2)^{-1/2}\\exp{\\left( -\\frac{1}{2\\sigma^2} (x-\\mu)^2 \\right)}$$\n",
    "\n",
    "* **Multivariate:**\n",
    "\n",
    ">$$p(\\mathbf{x|μ,Σ})=\\det{(2\\pi\\mathbf{Σ})}^{-1/2}\\exp{ \\left( -\\frac{1}{2}(\\mathbf{x-μ})^T\\mathbf{Σ}^{-1}(\\mathbf{x-μ})\\right) }$$\n",
    "\n",
    "* **Conditionals and Marginals are also Gaussian:**\n",
    "\n",
    "><img src=\"images/image04.png\" width=600>\n",
    "\n",
    "* **Algebra:**\n",
    "\n",
    ">$$p(\\mathbf{x,y})=p \\left( \\begin{bmatrix} \\mathbf{x} \\\\ \\mathbf{y} \\end{bmatrix} \\right) = \\mathcal{N} \\left( \\begin{bmatrix} \\mathbf{a} \\\\ \\mathbf{b} \\end{bmatrix} , \\begin{bmatrix} \\mathbf{A} & \\mathbf{B} \\\\ \\mathbf{B}^T & \\mathbf{C} \\end{bmatrix} \\right)$$\n",
    ">$$\\;$$\n",
    ">$$\\Rightarrow p(\\mathbf{x})=\\mathcal{N}(\\mathbf{a,A})$$\n",
    ">$$\\;$$\n",
    ">$$\\Rightarrow p(\\mathbf{x}|\\mathbf{y})=\\mathcal{N}(\\mathbf{a+BC}^{-1}(\\mathbf{y-b}),\\mathbf{A-BC}^{-1}\\mathbf{B}^T)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Gaussian Process\n",
    "\n",
    "* **Definition:**\n",
    "\n",
    ">* A **Gaussian Process** is a collection of random variables, any finite number of which have (consistent) Gaussian distributions\n",
    ">* It is fully specified by the **mean function** $\\mathcal{m}(\\mathcal{x})$ and **covariance function** $\\mathcal{k}(x,x')$\n",
    ">\n",
    ">$$f \\; \\text{~} \\; \\mathcal{GP}(m,k)$$\n",
    "\n",
    "* **Marginalisation Property:**\n",
    "\n",
    ">$$p(\\mathbf{x})=\\mathcal{N}(\\mathbf{a,A})$$\n",
    "\n",
    "* **Sequential Generation:**\n",
    "\n",
    ">$$p(f_n,f_{<n})= \\mathcal{N} \\left( \\begin{bmatrix} \\mathbf{a} \\\\ \\mathbf{b} \\end{bmatrix} , \\begin{bmatrix} \\mathbf{A} & \\mathbf{B} \\\\ \\mathbf{B}^T & \\mathbf{C} \\end{bmatrix} \\right)$$\n",
    ">$$\\;$$\n",
    "\n",
    ">$$p(f_n|f_{<n})=\\mathcal{N}(\\mathbf{a+BC}^{-1}(f_{<n}-\\mathbf{b}),\\mathbf{A-BC}^{-1}\\mathbf{B}^T)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Non-Parametric Gaussian Process Models\n",
    "\n",
    "* In non-parametric model, the **parameters** are the function itself\n",
    "* **Gaussian Likelihood:**\n",
    "\n",
    ">$$p(\\mathbf{y}|\\mathbf{x},f,\\mathcal{M}_i) \\;\\text{~}\\; \\mathcal{N}(\\mathbf{f},\\sigma^2_{noise}\\mathbf{I})$$\n",
    "\n",
    "* **Gaussian Process Prior:**\n",
    "\n",
    ">$$p(f|\\mathcal{M}_i) \\;\\text{~}\\; \\mathcal{GP}(m \\equiv 0,k)$$\n",
    "\n",
    "* **Gaussian Process Posterior:**\n",
    "\n",
    ">$$p(f|\\mathbf{x},\\mathbf{y},\\mathcal{M}_i) \\;\\text{~}\\; \\mathcal{GP}(m_{post},k_{post})$$\n",
    ">$$\\;$$\n",
    ">\\begin{align}\n",
    "m_{post}(x)&=\\mathbf{k}(x,\\mathbf{x})[K(\\mathbf{x},\\mathbf{x})+\\sigma^2_{noise}\\mathbf{I}]^{-1}\\mathbf{y}\\\\\n",
    "k_{post}(x,x')&=k(x,x')-\\mathbf{k}(x,\\mathbf{x})[K(\\mathbf{x},\\mathbf{x})+\\sigma^2_{noise}\\mathbf{I}]^{-1}\\mathbf{k}(\\mathbf{x},x')\n",
    "\\end{align}\n",
    "\n",
    "* **Gaussian Predictive:**\n",
    "\n",
    ">$$p(y_*|x_*,\\mathbf{x},\\mathbf{y},\\mathcal{M}_i) \\;\\text{~}\\; \\mathcal{N}\\left(\\mathbf{k}(x_*,\\mathbf{x})^T[K+\\sigma^2_{noise}\\mathbf{I}]^{-1}\\mathbf{y}\\\\,k(x_*,x_*)-\\mathbf{k}(x_*,\\mathbf{x})^T[K+\\sigma^2_{noise}\\mathbf{I}]^{-1}\\mathbf{k}(x_*,\\mathbf{x})\\right)$$\n",
    "\n",
    "* **Mean:** Linear in 2 Ways\n",
    "\n",
    ">$$\\mathbf{k}(x_*,\\mathbf{x})^T[K(\\mathbf{x},\\mathbf{x})+\\sigma^2_{noise}\\mathbf{I}]^{-1}\\mathbf{y}=\\sum^{N}_{n=1}{\\beta_n y_n}=\\sum^{N}_{n=1}{\\alpha_nk(x_*,x_n)}$$\n",
    "\n",
    "* **Variance:** Difference between 2 Terms\n",
    "\n",
    ">$$k(x_*,x_*)-\\mathbf{k}(x_*,\\mathbf{x})^T[K+\\sigma^2_{noise}\\mathbf{I}]^{-1}\\mathbf{k}(x_*,\\mathbf{x})$$\n",
    ">* 1st term: **prior variance**\n",
    ">* 2nd term: **how much the data $x$ has explained**\n",
    ">* **NOTE:** the variance is independent of the observed outputs $\\mathbf{y}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. GP Marginal Likelihood and Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Linear in the Parameters Models and GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Finite and Infinite Basis GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
