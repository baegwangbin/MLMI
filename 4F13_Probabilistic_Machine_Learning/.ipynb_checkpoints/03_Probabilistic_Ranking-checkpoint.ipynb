{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "* **Goal:**\n",
    "\n",
    ">*What is the probability that player 1 defeats player 2?*\n",
    "\n",
    "* **Generative Model for Game Outcomes:**\n",
    "\n",
    ">* Player has **skills** $\\rightarrow$ compute skill difference\n",
    "\n",
    ">$$s = w_1 - w_2$$\n",
    "\n",
    ">* **Add noise**\n",
    "\n",
    ">$$t = s + n \\;\\;\\;\\text{where}\\;\\;\\; n \\text{~} \\mathcal{N}(0,1)$$\n",
    "\n",
    ">* **Computer game outcome**\n",
    "\n",
    ">$$y=\\text{sign}(t)= \\Bigg\\{ \\begin{matrix} +1 \\rightarrow \\text{Player 1 wins}\\\\ -1 \\rightarrow \\text{Player 1 wins}\\end{matrix}$$\n",
    "\n",
    ">* **Probability that player 1 wins**\n",
    "\n",
    ">$$p(t|w_1,w_2) = \\mathcal{N}(t;w_1-w_2,1)$$\n",
    "\n",
    ">$$p(y=1|w_1,w_2)=p(t>0|w_1,w_2)=\\Phi(w_1-w_2)$$\n",
    "\n",
    ">$$\\Phi(x)=\\int^x_{-\\infty} \\mathcal{N}(z;0,1)dz = \\int^\\infty_0 \\mathcal{N}(z;x,1)dz$$\n",
    "\n",
    ">* **Likelihood**\n",
    "\n",
    ">$$p(y|w_1,w_2) = \\Phi(y(w_1-w_2))$$\n",
    "\n",
    "* **TrueSkill: a probabilistic skill rating system:**\n",
    "\n",
    ">* **Prior**\n",
    "\n",
    ">$$p(w_i) = \\mathcal{N}(w_i|\\mu_i,\\sigma^2_i)$$\n",
    "\n",
    ">* **Likelihood**\n",
    ">  * $p(s|w_1,w_2)$: delta fn.\n",
    ">  * $p(y|t)$: step fn.\n",
    "\n",
    ">$$p(y|w_1,w_2)=\\iint p(y|t)p(t|s)p(s|w_1,w_2)dsdt$$\n",
    "\n",
    "\n",
    "\n",
    ">* **Posterior:** no longer Gaussian / does not factorise / looks like a high-dim ball\n",
    "\n",
    ">\\begin{align}\n",
    "p(w_1,w_2|y) &= \\frac{p(w_1)p(w_2)p(y|w_1,w_2)}{\\iint p(w_1)p(w_2)p(y|w_1,w_2)dw_1 dw_2} \\\\\n",
    "&= \\frac{\\mathcal{N}(w_1;\\mu_1,\\sigma_1^2)\\mathcal{N}(w_2;\\mu_2,\\sigma_2^2) \\Phi(y(w_1-w_2))}{\\iint \\mathcal{N}(w_1;\\mu_1,\\sigma_1^2)\\mathcal{N}(w_2;\\mu_2,\\sigma_2^2)\\Phi(y(w_1-w_2)) dw_1dw_2}\n",
    "\\end{align}\n",
    "\n",
    ">* **Normalising constant:** have closed form\n",
    "\n",
    ">$$p(y) = \\Phi \\left( \\frac{y(\\mu_1-\\mu_2)}{\\sqrt{1+\\sigma^2_1+\\sigma^2_1}} \\right) \\;\\;\\;\\rightarrow\\;\\;\\; \\text{smoother version of the likelihood}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gibbs Sampling\n",
    "\n",
    "* **Q. How do we integrate wrt an intractable posterior?**\n",
    "* **The original integral**\n",
    "\n",
    ">$$\\mathbb{E}_{p(\\mathbf{x})}[\\phi(\\mathbf{x})] = \\bar{\\phi} = \\int \\phi(\\mathbf{x}) p(\\mathbf{x}) \\text{d}\\mathbf{x} \\;\\;\\; , \\;\\;\\; \\mathbf{x} \\in \\mathbb{R}^D$$\n",
    "\n",
    "* **Numerical integration on a grid** (practical only to $D \\leq 4$)\n",
    "\n",
    ">$$\\int{\\phi(\\mathbf{x})p(\\mathbf{x})\\text{d}\\mathbf{x}} \\approx \\sum^T_{\\tau=1} \\phi(\\mathbf{x}^{(\\tau)}) p(\\mathbf{x}^{(\\tau)}) \\Delta \\mathbf{x}$$\n",
    "\n",
    "* **Monte Carlo**\n",
    "\n",
    ">$$\\mathbb{E}_{p(\\mathbf{x})} [\\phi(\\mathbf{x})] \\approx \\hat{\\phi} = \\frac{1}{T} \\sum^T_{\\tau=1} \\phi(\\mathbf{x}^{(\\tau)}) \\;\\;\\;,\\;\\;\\; \\mathbf{x}^{(\\tau)} \\text{ ~ } p(\\mathbf{x})$$\n",
    "\n",
    ">* $\\hat{\\phi}$: unbiased estimate with\n",
    "\n",
    ">$$\\mathbb{V}[\\hat{\\phi}] = \\frac{\\mathbb{V}[\\phi]}{T} \\;\\;\\;,\\;\\;\\; \\mathbb{V}[\\phi] = \\int \\left( \\phi(\\mathbf{x})-\\bar{\\phi} \\right)^2 p(\\mathbf{x}) \\text{d} \\mathbf{x}$$\n",
    "\n",
    ">* **NOTE:** the variance in independent of the dimension of $\\mathbf{x}$\n",
    "\n",
    "* **Markov Chain Monte Carlo $q(x'|x)$**\n",
    "\n",
    ">$$\\mathbf{x} \\rightarrow \\mathbf{x}' \\rightarrow \\mathbf{x}'' \\rightarrow \\mathbf{x}''' \\rightarrow \\cdots$$\n",
    "\n",
    ">* This will eventually generate dependent samples from $p(\\mathbf{x})$\n",
    "\n",
    "* **Gibbs Sampling - Definition**\n",
    "\n",
    ">$$x'_i \\sim p(x_i|x_1,...,x_{i-1},x_{i+1},...,x_D)$$\n",
    "\n",
    ">* For $x_i$, sample a new value from the conditional distribution of $x_i$ given all other variables\n",
    "\n",
    "* **Gibbs Sampling - Advantage & Disadvantage**\n",
    "\n",
    ">* **Advantage:** \n",
    ">  * Parameter free algorithm, applicable if we know how to sample from the conditional distributions\n",
    ">  * It can be shown that this will eventually generate dependent samples from $p(\\mathbf{x})$\n",
    ">  * Sampling from a joint distribution $\\rightarrow$ sampling from a sequence of univariate conditional distributions\n",
    "\n",
    ">* **Disadvantage:** \n",
    ">  * Correlation between consecutive samples \n",
    ">    * $\\rightarrow$ Samples are thinned (e.g.  every 10th or 100th)\n",
    ">  * Initial convergence\n",
    ">    * $\\rightarrow$ Initial samples are discarded (**what is convergence?**)\n",
    ">  * Dependence on starting point\n",
    ">    * $\\rightarrow$ Run several Gibbs samplers & compare\n",
    ">  * Challenging to judge the ***effective correlation length*** of a Gibbs sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gibbs Sampling in Trueskill\n",
    "\n",
    "* **Gibbs Sampling in Trueskill**\n",
    "\n",
    ">* Joint distribution: intractable\n",
    ">* Performance given skills & Skills given performances: tractable\n",
    ">* **Notation:**\n",
    ">  * $g=1,...,G \\text{games}$\n",
    ">  * $I_g: \\text{Player 1} \\;\\;\\;,\\;\\;\\; J_g: \\text{Player 2}$\n",
    ">  * $y_g=+1$ if $I_g$ wins & $y_g=-1$ if $J_g$ wins\n",
    "\n",
    "* **Algorithm** (repeat 2&3)\n",
    "\n",
    ">* **Step 1:** Initialise $\\mathbf{w}$ e.g. from the prior $p(w)$\n",
    "\n",
    ">* **Step 2:** Sample the performance differences from their conditional posteriors\n",
    "\n",
    ">$$p(t_g|w_{I_g},w_{J_g},y_g) \\propto \\delta (y_g-\\text{sign}(t_g))\\mathcal{N}(t_g;w_{I_g}-w_{J_g},1)$$\n",
    "\n",
    ">* **Step 3:** Jointly sample the skills from the conditional posterior\n",
    "\n",
    ">$$p(\\mathbf{w}|\\mathbf{t},\\mathbf{y}) = p(\\mathbf{w}|\\mathbf{t})\\propto p(\\mathbf{w}) \\prod^G_{g=1} p(t_g|w_{I_g},w_{J_g})$$\n",
    "\n",
    ">* $p(\\mathbf{w}|\\mathbf{t}) = \\mathcal{N}(\\mathbf{w};\\mu,\\Sigma)$\n",
    ">* $p(\\mathbf{w}) = \\mathcal{N}(\\mathbf{w};\\mu_0,\\Sigma_0)$\n",
    ">* $p(t_g|w_{I_g},w_{J_g}) \\propto \\mathcal{N}(\\mathbf{w};\\mu_g, \\Sigma_g)$\n",
    "\n",
    "* **Gaussian Identities**\n",
    "\n",
    ">\\begin{align}\n",
    "p(t_g|w_{I_g},w_{J_g}) &\\propto \\exp \\left( -\\frac{1}{2}(w_{I_g}-w_{J_g}-t_g)^2 \\right) \\\\\n",
    "&\\propto \\mathcal{N} \\left( -\\frac{1}{2} \\left( \\begin{matrix} w_{I_g}-\\mu_1 \\\\ w_{J_g}-\\mu_2 \\end{matrix} \\right)^T \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix} \\left( \\begin{matrix} w_{I_g}-\\mu_1 \\\\ w_{J_g}-\\mu_2 \\end{matrix} \\right) \\right) \n",
    "\\end{align}\n",
    "\n",
    ">* Since $\\mu_1 - \\mu_2 = t_g$\n",
    "\n",
    ">$$\\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix} \\left( \\begin{matrix} \\mu_1 \\\\ \\mu_2 \\end{matrix} \\right) = \\left( \\begin{matrix} t_g \\\\ -t_g \\end{matrix} \\right)$$\n",
    "\n",
    ">* Product of Gaussian\n",
    "\n",
    ">$$\\mathcal{N}(\\mathbf{w};\\mu_a,\\Sigma_a) \\mathcal{N}(\\mathbf{w};\\mu_b, \\Sigma_b) = z_c \\mathcal{N}(\\mathbf{w};\\mu_c,\\Sigma_c)$$\n",
    "\n",
    ">$$\\Sigma_c^{-1}=\\Sigma_a^{-1}+\\Sigma_b^{-1} \\;\\;\\;,\\;\\;\\; \\mu_c = \\Sigma_c(\\Sigma_a^{-1}\\mu_a + \\Sigma_b^{-1}\\mu_b)$$\n",
    "\n",
    ">* **Conditional Posterior**\n",
    "\n",
    ">$$\\Sigma^{-1}=\\Sigma^{-1}_0+\\sum^G_{g=1} \\Sigma^{-1}_g \\;\\;\\;,\\;\\;\\; \\mu=\\Sigma \\left( \\Sigma^{-1}_0 \\mu_0 + \\sum^G_{g=1} \\Sigma^{-1}_g \\mu_g \\right)$$\n",
    "\n",
    ">$$\\tilde{\\Sigma}^{-1} = \\sum^G_{g=1} \\Sigma^{-1}_g \\;\\;\\;,\\;\\;\\; \\tilde{\\mu} = \\sum^G_{g=1} \\Sigma^{-1}_g \\mu_g$$\n",
    "\n",
    ">* Each game precision $\\Sigma_g^{-1}$ contains only 4 non-zero entries\n",
    "\n",
    "* **The combined precision & mean**\n",
    "\n",
    ">\\begin{align}\n",
    "[\\tilde{\\Sigma}^{-1}]_{ii} &= \\sum^G_{g=1} \\delta(i-I_g)+\\delta(i-J_g) \\\\\n",
    "[\\tilde{\\Sigma}^{-1}]_{i \\neq j} &= -\\sum^G_{g=1} \\delta(i-I_g)\\delta(j-J_g) + \\delta(i-J_g)\\delta(j-I_g) \\\\\n",
    "\\tilde{\\mu}_i &= \\sum^G_{g=1} t_g \\left( \\delta(i-I_g)+\\delta(i-J_g) \\right)\n",
    "\\end{align}\n",
    "\n",
    "><img src=\"images/image23.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
