{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Statistical Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. What is SMT?\n",
    "\n",
    "* **Translation:** search for the best hypothesis under a statistical model\n",
    "\n",
    ">$$\\hat{t} = \\underset{t \\in \\mathcal{T}}{\\text{argmax}} \\; P(t|s) = \\underset{t \\in \\mathcal{T}}{\\text{argmax}} \\; P(s|t) P(t)$$\n",
    "\n",
    ">* $s$: input source sentence / $t$: target word sequence\n",
    ">* $P(t|s)$: **Direct Translation (NMT)**\n",
    ">* $P(s|t)$: **Translation Model** / estimated from parallel texts\n",
    ">* $P(t)$: **Language Model** / estimated from monolingual texts\n",
    "\n",
    "* **SMT and ASR**\n",
    "\n",
    "><img src = 'images/image2_01.png' width=400>\n",
    "\n",
    ">* Both can be formulated using a **Source-Channel model**\n",
    ">* Both are found as a **MAP estimates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Alignment\n",
    "\n",
    "* **Parallel Texts**\n",
    "\n",
    ">* Aligned elements in parallel texts are translations of each other\n",
    "\n",
    "* **Alignment**\n",
    "\n",
    ">* Multi-level, hierarchical process (words $\\in$ sentences $\\in$ paragraphs $\\in$ documents $\\in$ collections)\n",
    ">* Can be obtained manually / semiautomatically / automatically\n",
    "\n",
    ">$$\\text{Alignment variable: } a_j = i \\;\\;\\;\\Leftrightarrow\\;\\;\\; e_i \\leftrightarrow f_j$$\n",
    "\n",
    ">$$\\text{Alignment model: } P(A|s,f) \\;\\;\\;\\text{where}\\;\\;\\; A = \\{ (i,j) : 1 \\leq i \\leq I, 1 \\leq j \\leq J\\}$$\n",
    "\n",
    ">* **Sentence alignment:** markers indicate start & end of translation segments (can be sub-sentence units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Quality of MT\n",
    "\n",
    "* **Human Metrics** (e.g. binary, scaled, preference scores) $\\rightarrow$ slow and costly\n",
    "* **Humans in the Loop**\n",
    "\n",
    "><img src = 'images/image2_02.png' width=300>\n",
    "\n",
    ">* Adapt systems to human feedbacks (e.g. preferences, suggestions)\n",
    ">* Typically, only 0.5% of the feedbacks are useful, but they are extremely useful\n",
    ">* Agreement between experts $\\approx$ Weighted agreement between 5 non-experts\n",
    "\n",
    "* **BLEU:** MT metric based on n-gram precision\n",
    "\n",
    ">* **NOTE:** BLEU is not an absolute measure. It only indicates **relative quality**\n",
    "\n",
    ">$$BLEU(T,R) = \\gamma(T,R) \\exp \\left( \\sum^N_{n=1} \\frac{1}{N} \\log p_n (T,R) \\right)$$\n",
    "\n",
    ">* **Geometrical mean** of the **n-gram precisions** (typically $N=4$)\n",
    "\n",
    ">$$\\log p_n (T,R) = \\frac{\\sum_i \\bar{c}^i_n}{\\sum_i c^i_n}$$\n",
    "\n",
    ">* $c^i_n$: no. of hypothesized n-grams\n",
    ">* $\\bar{c}^i_n$: no. of correct n-grams, contribution of each distinct n-gram is clipped to the maximum no. of occurences in any one reference\n",
    "\n",
    ">* **Brevity penalty** \n",
    "\n",
    ">$$r = \\sum_i \\min \\big\\{ \\big|R^i_{(1)}\\big|,\\big|R^i_{(2)}\\big|,\\big|R^i_{(3)}\\big|,\\big|R^i_{(4)}\\big| \\big\\} \n",
    "\\;\\;\\;,\\;\\;\\; c = \\sum_i |T^i|$$\n",
    "\n",
    ">$$\\gamma(T,R) = \\Bigg\\{ \\begin{matrix}1 && c>r \\\\ \\exp(1-\\frac{r}{c}) && c\\leq r \\end{matrix}$$\n",
    "\n",
    "* Other **Automatic Metrics - Lexical Similarity** \n",
    "\n",
    ">* **WER**(Word Error Rate): \n",
    "\n",
    ">$$WER(T,R) = \\frac{Ins + Del + Sub}{N}$$\n",
    "\n",
    ">* **TER**(Translation Edit Rate): \n",
    "\n",
    ">$$TER(T,R) = \\frac{Ins + Del + Sub + Shft}{N}$$\n",
    "\n",
    ">* **METEOR** (harmonic mean of unigram precision and recall): penalty $p \\propto$ no. of alignment chuncks between hyp and refs / accepts synonyms and considers stemming\n",
    "\n",
    ">$$\\frac{10PR}{R+9P} \\times (1-p)$$\n",
    "\n",
    ">* **NIST** (variant of BLEU): assigns different value to each matching n-gram according to information gain statistics / less sensitive to brevity penalty (gaussian length distribution near average ref. length)\n",
    "\n",
    ">* **GTM**(Geometric Translation Mean), **WNM**(Weighted N-gram Model), **CER**(Classification Error Rate), **ROUGE** & **ORANGE** (summary evaluation),...\n",
    "\n",
    "* Other **Automatic Metrics - Linguishtically-informed** \n",
    "\n",
    ">* **Shallow syntactic similarity** - part-of-speech, lemmas, phrase chunks\n",
    ">* **Syntactic similarity** - dependency trees, head-word chains, constituency parsing\n",
    ">* **Semantic similarity** - named entities, semantic roles, discourse representation\n",
    "\n",
    "\n",
    "* **Variability in References $\\rightarrow$ HyTER** \n",
    "\n",
    ">* Meaning-equivalent semantics for translation evaluation\n",
    ">* Creates **FSAs** of translations $\\rightarrow$ measure quality by **string edit distance**\n",
    ">* Median no. of translations: $+100M/sentence$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
