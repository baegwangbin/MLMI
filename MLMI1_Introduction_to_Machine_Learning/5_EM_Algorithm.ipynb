{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. EM Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Mixture of Gaussian: Generative Model\n",
    "\n",
    "* **Sample cluster membership $\\rightarrow$ Sample data-value**\n",
    "\n",
    ">$$p(s_n=k|\\theta)=\\pi_k \\;\\;\\;\\text{where}\\;\\;\\; \\sum^K_{k=1}\\pi_k=1$$\n",
    "\n",
    ">$$p(\\mathbf{x}_n|s_n=k,\\theta)=\\mathcal{N}(\\mathbf{x}_n;\\mathbf{m}_k,\\Sigma_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. KL Divergence\n",
    "\n",
    ">$$\\mathcal{KL}(p_1(z)||p_2(z))=\\sum_z p_1(z)\\log{\\frac{p_1(z)}{p_2(z)}}$$\n",
    "\n",
    ">* **Gibb's Inequality:** $\\mathcal{KL}(p_1(z)||p_2(z))\\geq0\\;\\;\\;\\text{equality at } p_1(z)=p_2(z)$\n",
    ">* **Non-Symmetric:** $\\mathcal{KL}(p_1(z)||p_2(z))\\neq\\mathcal{KL}(p_2(z)||p_1(z))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "b868be8d070d43819ab213fde0a8c2c8"
   },
   "source": [
    "## 5.3. EM Algorithm\n",
    "\n",
    "* **Free Energy**: Lower bound on LL\n",
    "\n",
    ">$$\\mathcal{F}(q(s),\\theta)=\\log p(x|\\theta) - \\sum_s q(s)\\log{\\frac{q(s)}{p(s|x,\\theta)}}$$\n",
    "\n",
    "* **E Step:** For fixed $\\theta{t-1}$, maximise lower bound $\\mathcal{F}(q(s),\\theta_{t-1})$ wrt $q(s)$\n",
    "\n",
    ">$$q_t(s)=p(s|x,\\theta_{t-1})$$\n",
    "\n",
    "* **M Step:** For fixed $q_t(s)$, maximise lower bound $\\mathcal{F}(q_t(s),\\theta)$ wrt $\\theta$\n",
    "\n",
    ">$$\\mathcal{F}(q(s),\\theta)=\\sum_s q(s)\\log(p(x|s,\\theta)p(s|\\theta))-\\sum_s q(s)\\log q(s)$$\n",
    "\n",
    ">$$\\theta_t=\\underset{\\theta}{\\text{argmax}}\\sum_s q_t(s) \\log (p(x|s,\\theta)p(s|\\theta)) $$\n",
    "\n",
    "* **LL cannot decrease**\n",
    "\n",
    ">$$\\log p(x|\\theta_{t-1}) \\overset{\\text{E step}}{=} \\mathcal{F}(q_t(s), \\theta_{t-1}) \\overset{\\text{M step}}{\\leq} \\mathcal{F}(q_t(s),\\theta_t) \\overset{\\text{lower bound}}{\\leq} \\log p(x|\\theta_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4. EM - Application to 1D data\n",
    "\n",
    "* **Probability of the observations given the latent variables and the parameters:**\n",
    "\n",
    ">$$p(x_n|s_n=k,\\theta)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_k}}\\exp\\left(-\\frac{1}{2\\sigma_k^2}(x_n-\\mu_k)^2\\right)$$\n",
    "\n",
    "* **Prior on latent variables**\n",
    "\n",
    ">$$p(s_n=k)=\\pi_k$$\n",
    "\n",
    "* **E Step: fills in the values of the hidden variables** \n",
    "\n",
    ">\\begin{align}\n",
    "q(s_n=k)=p(s_n=k|x_n,\\theta)&\\propto p(x_n,s_n=k|\\theta)\\\\\n",
    "&=\\frac{\\pi_k}{\\sqrt{2\\pi\\sigma^2_k}}\\exp\\left(-\\frac{1}{2\\sigma_k^2}(x_n-\\mu_k)^2\\right)=u_{nk}\n",
    "\\end{align}\n",
    "\n",
    ">$$q(s_n=k)=r_{nk}=\\frac{u_{nk}}{u_n} \\;\\;\\;\\text{where}\\;\\;\\; u_n=\\sum^K_{k=1}u_{nk}$$\n",
    "\n",
    ">* $r_{nk}$: ***Responsibility*** that component $k$ takes for datapoint $n$\n",
    "\n",
    "* **M Step: performs supervised learning with known (soft) cluster assignments**\n",
    "\n",
    "\n",
    ">$$\\mathcal{F}(q(s),\\theta) = \\sum^N_{n=1} \\sum^K_{k=1} q(s_n=k) \\left[ \\log (\\pi_k) - \\frac{1}{2\\sigma^2_k} (x_n - \\mu_k)^2 - \\frac{1}{2} \\log (\\sigma^2_k) \\right] + \\text{const.}$$\n",
    "\n",
    ">\\begin{align}\n",
    "\\frac{\\partial \\mathcal{F}}{\\partial \\mu_j} &= \\sum^N_{n=1} q(s_n = j) \\frac{x_n-\\mu_j}{\\sigma^2_j} = 0 &\\Rightarrow \\mu_j = \\frac{\\sum^N_{n=1} q(s_n = j)x_n}{\\sum^N_{n=1} q(s_n=j)} \\\\\n",
    "\\frac{\\partial \\mathcal{F}}{\\partial \\sigma^2_j} &= \\sum^N_{n=1} q(s_n = j) \\left[ \\frac{(x_n-\\mu_j)^2}{2\\sigma^4_j} - \\frac{1}{2\\sigma^2_j} \\right] = 0 &\\Rightarrow \\sigma^2_j = \\frac{\\sum^N_{n=1} q(s_n = j)(x_n-\\mu_j)^2}{\\sum^N_{n=1} q(s_n=j)} \\\\\n",
    "\\frac{\\partial [\\mathcal{F} + \\lambda(1-\\sum_k \\pi_k)]}{\\partial \\pi_j} &= \\sum^N_{n=1} \\frac{q(s_n=j)}{\\pi_j} - \\lambda = 0 &\\Rightarrow \\pi_j = \\frac{1}{N} \\sum^N_{n=1} q(s_n=j)\n",
    "\\end{align}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
